{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaffd263",
   "metadata": {},
   "source": [
    "## An In-depth Exploration of US Job Market by analyzing LinkedIn Job Postings using Natural Language Processing Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7398af41",
   "metadata": {},
   "source": [
    "## Data ingestion and preprocesing\n",
    "We firstly need to read the webscraped dataset and explore its contents before we begin the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de1dda69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "# importing necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08e7c598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset\n",
    "data = pd.read_csv('/Users/juliabarsow/Desktop/thesis/project_code/postings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f44e1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123849, 31)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "197bf12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing rows of description:  7\n"
     ]
    }
   ],
   "source": [
    "#check how many descriptions are missing as this is the most important column\n",
    "print(\"Missing rows of description: \",data['description'].isnull().sum())\n",
    "\n",
    "#drop rows with missing descriptions\n",
    "data = data.dropna(subset=['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48f3c4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Marketing Coordinator',\n",
       " 'Mental Health Therapist/Counselor',\n",
       " 'Assitant Restaurant Manager',\n",
       " 'Senior Elder Law / Trusts and Estates Associate Attorney',\n",
       " ' Service Technician',\n",
       " 'Economic Development and Planning Intern',\n",
       " 'Producer',\n",
       " 'Building Engineer',\n",
       " 'Respiratory Therapist',\n",
       " 'Worship Leader',\n",
       " 'Inside Customer Service Associate',\n",
       " 'Project Architect',\n",
       " \"Appalachian Highlands Women's Business Center\",\n",
       " 'Structural Engineer',\n",
       " 'Senior Product Marketing Manager',\n",
       " 'Osteogenic Loading Coach',\n",
       " 'Administrative Coordinator',\n",
       " 'Customer Service / Reservationist',\n",
       " 'Content Writer, Communications',\n",
       " 'Controller',\n",
       " 'Physician Assistant',\n",
       " 'Licensed Acupuncturist',\n",
       " 'Software Engineer',\n",
       " 'Sheet Metal Fabricator',\n",
       " 'Personal Injury Attorney',\n",
       " 'NPE 2024 Exhibition Event Worker',\n",
       " 'Loan Coordinator',\n",
       " 'General Laborer',\n",
       " 'Swim Instructor',\n",
       " 'Administrative Assistant',\n",
       " 'Service / Construction Technician',\n",
       " 'Legal Secretary',\n",
       " 'Salesperson',\n",
       " 'Registered Nurse',\n",
       " 'Marketing & Office Coordinator',\n",
       " 'Software Support Specialist',\n",
       " 'Coordinator for Multicultural Student Organizations',\n",
       " 'Barber',\n",
       " 'Production Planner (Food Technologist)',\n",
       " 'Embryologist',\n",
       " 'Chief Operating Officer',\n",
       " 'Associate Attorney',\n",
       " 'HVAC Technician',\n",
       " 'External Mortgage Loan Officer',\n",
       " 'TREC licensed Professional Home Inspector',\n",
       " 'Manager, Retail Pharmacy',\n",
       " 'Commercial Property Manager',\n",
       " 'SALES',\n",
       " 'Transactional Attorney',\n",
       " 'Blog writer and virtual assistant',\n",
       " 'Marketing Specialist',\n",
       " 'Sales Associate Natural Food Products',\n",
       " 'Industrial Sales Representative',\n",
       " 'National Sales Manager',\n",
       " 'Reps manager',\n",
       " 'Montessori Lead Guide, Primary',\n",
       " 'Director of Training',\n",
       " 'Office Manager',\n",
       " 'Social Media Coordinator',\n",
       " 'Equity Institutional Sales Position',\n",
       " 'Front Desk Administrator',\n",
       " 'Social Security Specialist / Retirement Benefit Advisor (Remote)',\n",
       " 'Board Certified Behavior Analyst',\n",
       " 'Lead Installer',\n",
       " 'Med-RN ER',\n",
       " 'Workflow Coordinator Hospitality - Mon - Fri 8am-5pm',\n",
       " 'Sales Representative',\n",
       " 'Dental Hygienist - choose your shift',\n",
       " 'FP&A Analyst',\n",
       " 'Entry Level Oracle Financial Technology Consultant',\n",
       " 'Maintenance Mechanic',\n",
       " 'Trade Review Principal',\n",
       " 'Mover/Junk Hauler/Crew Member',\n",
       " 'Dental CAD/CAM Designer - $20-$30/hour',\n",
       " 'Production Planner',\n",
       " 'Customer Service Representative',\n",
       " 'Associate Planner',\n",
       " 'Full Stack Engineer',\n",
       " 'Computer Scientist',\n",
       " 'Front end specialist',\n",
       " 'Client Service Associate',\n",
       " 'Sales and Design consultant',\n",
       " 'Staff Accountant',\n",
       " 'Quality Assurance Manager',\n",
       " 'Validation Engineer, Labware LIMS',\n",
       " 'Intern- Business Analytics',\n",
       " 'Service Manager',\n",
       " 'Robot Monitor & Maintenance Technician',\n",
       " 'Director of Public Works',\n",
       " 'Fire Sprinkler Designer',\n",
       " 'Assistant Director of Admission, Midwest Regional Representative',\n",
       " 'Executive Assistant',\n",
       " 'Director of Operations',\n",
       " 'Service Coordinator',\n",
       " 'Fundraising Associate',\n",
       " 'Professional Window Cleaning Technician',\n",
       " 'Construction Project Manager',\n",
       " 'Administrative Assistant - CONCUR',\n",
       " 'Seasonal Office Administrator',\n",
       " 'Digital Marketing Intern',\n",
       " 'Project Engineer',\n",
       " 'Architect/Project Manager',\n",
       " 'Histologist - HT',\n",
       " 'Salesforce Vlocity Developer',\n",
       " 'Events & Communications Assistant',\n",
       " 'Client Service Associate / Practice Manager',\n",
       " 'Architectural Designer',\n",
       " 'Marketing & Communications ‚Äì Content Writer Internship',\n",
       " 'Heavy Equipment Operator',\n",
       " 'Recruitment Manager',\n",
       " 'Data Architect',\n",
       " 'SAP BTP',\n",
       " 'Operations Specialist',\n",
       " 'Commercial Construction Project Managers/Superintendents',\n",
       " 'CPA',\n",
       " 'HR & Administrative Assistant',\n",
       " 'Contract Administrator',\n",
       " 'Project Manager',\n",
       " 'Director of Communications and Digital Diplomacy',\n",
       " 'Director, Investment Sales',\n",
       " 'Pharmacy Technician',\n",
       " 'Sanitation Supervisor',\n",
       " 'Trial Attorney',\n",
       " 'Anaplan Developer',\n",
       " 'Senior Account Manager',\n",
       " 'Finishing Editor',\n",
       " 'Account Executive - Mid-Market',\n",
       " 'Administrative Assistant Project Coordinator',\n",
       " 'Technical Product and IT Manager for Data Center Dedicated Server Leasing',\n",
       " 'Motion Graphic Designer and Film Editor',\n",
       " 'Social Media Manager and Graphic Designer',\n",
       " 'Licensed Mental Health Counselor/ Licensed Clinical Social Worker',\n",
       " 'Client Service Representative',\n",
       " 'Legal Assistant / Paralegal',\n",
       " 'Accounting Specialist',\n",
       " 'Client Relationship Specialist',\n",
       " 'Account Manager',\n",
       " 'Clinical Trainee / Pre-Liscneded Therapist',\n",
       " 'Owner',\n",
       " 'Tax Associate',\n",
       " 'Senior Developer',\n",
       " 'Energy and Asset Coordinator',\n",
       " 'Photonics Layout Intern',\n",
       " 'Summer Intern for Women International Company',\n",
       " 'Social Media Marketing Specialist Internship',\n",
       " 'Chief Executive Officer',\n",
       " 'Leasing & Property Management Specialist (Part-Time with Growth Potential)',\n",
       " 'Group Fitness Instructor',\n",
       " 'Commercial Litigation Associate Attorney',\n",
       " 'Assistant Director',\n",
       " 'Marketing Manager',\n",
       " 'Associate Brand Manager',\n",
       " 'Customer Success Manager',\n",
       " 'Grants Writer - Subcontract',\n",
       " 'Retail Salesperson',\n",
       " 'Administrator of College & Career Development',\n",
       " 'Eastern Regional Sales Coordinator',\n",
       " 'Java architect / Lead Java developer',\n",
       " 'Field Operations Specialist',\n",
       " 'Enterprise Data & Analytics Infrastructure Manager',\n",
       " 'Heating Air Conditioning Technician',\n",
       " 'Brand Representative',\n",
       " 'Mental Health Therapist',\n",
       " 'Inbound Call Center Specialist',\n",
       " 'Community Program Assistant',\n",
       " 'User Experience Designer',\n",
       " 'Corporate Controller',\n",
       " 'CT Technologist',\n",
       " 'Administrative Assistant Bookkeeper',\n",
       " 'Swahili Instructor',\n",
       " 'Elementary School Teacher',\n",
       " 'Industrial Business Development Manager',\n",
       " 'Private Fitness Instructor',\n",
       " 'Accounts Analyst',\n",
       " 'Sales and Application Engineer',\n",
       " 'Senior Software Engineer',\n",
       " 'Director of Sales',\n",
       " 'Drone-Car Engineer',\n",
       " '2L 2025 Summer Law Clerk',\n",
       " 'Scientific Project Manager for Food, Beverage, and Consumer Packaged Goods Industries (Project Architect | PA)',\n",
       " 'Maintenance Manager',\n",
       " 'Primary Care Leader Needed',\n",
       " 'Child Custody Recommending Counselor',\n",
       " 'Field Director',\n",
       " 'Sales Development Representative',\n",
       " 'Ophthalmic Technician',\n",
       " 'Commercial Auto Underwriter Assistant',\n",
       " 'Tool and Die Maker',\n",
       " 'Senior Mechanical Engineer',\n",
       " 'DDI Engineer',\n",
       " 'Mechanical Design Engineer',\n",
       " 'Quality Engineer',\n",
       " 'üåüüöÄüåä Make Waves with Your Sales Skills! Earn $2500-$3500/Week! üåäüöÄüåü',\n",
       " 'Montessori teacher for grades K-3',\n",
       " 'Medical Consultant',\n",
       " 'Skilled Painter for Fabrication Shop',\n",
       " 'URGENT!! Influencer Marketing Intern (100% WFH)',\n",
       " 'Blender Animator (Contract)',\n",
       " 'Yoga Teacher',\n",
       " 'Experienced Growth Consultants with OD/OCM experience',\n",
       " 'Project Assistant',\n",
       " 'Director of Finance',\n",
       " 'Car Salesperson',\n",
       " 'Executive Personal Assistant',\n",
       " 'MEP Engineer',\n",
       " 'School Counselor',\n",
       " 'Client Success Manager (Locums Tenens)',\n",
       " 'Receptionist',\n",
       " 'Accounts Payable Specialist',\n",
       " 'Crew Member',\n",
       " 'Senior Electronics Design Engineer',\n",
       " 'Level 1 Designer',\n",
       " 'Special Event Manager',\n",
       " 'Quality Assurance Specialist',\n",
       " 'Attending Physician',\n",
       " 'Pediatric Occupational Therapy',\n",
       " 'Sales Director - Part-Time - Remote',\n",
       " 'Request for Consultancy: Interim Managing Director',\n",
       " 'Board Member',\n",
       " 'Team Lead',\n",
       " 'Senior Retail Sales Associate',\n",
       " 'Interior Designer',\n",
       " 'FIELD SALES REPRESENTATIVE - North Carolina',\n",
       " 'Admin/HR/Customer Support',\n",
       " 'Fitness Sales General Manager',\n",
       " 'Mechanical Engineer',\n",
       " 'Web Developer',\n",
       " 'Bird Control Account Manager and Supervisor',\n",
       " 'Litigation Paralegal',\n",
       " 'Software Implementation Program Manager',\n",
       " 'Vice President - Engineering & Production Operation',\n",
       " 'Medical Assistant',\n",
       " 'Managed File Transfer Specialist (connect direct , NDM) | REMOTE ROLE',\n",
       " 'Inbound Sales & Onboarding Specialist',\n",
       " 'Senior Project Engineer',\n",
       " 'Technical Designer, Womans Denim Bottoms ',\n",
       " 'Admininistrative Assistant Intern',\n",
       " 'Manager',\n",
       " 'Clinical Pharmacist',\n",
       " 'Director Origination',\n",
       " 'Sales & Design Consultant',\n",
       " 'Cybersecurity Test Engineer ‚Äì Remote',\n",
       " 'Director of Compliance',\n",
       " 'Histology Supervisor',\n",
       " 'Editor',\n",
       " 'Digital Marketing Manager',\n",
       " 'Human Resources Manager',\n",
       " 'Litigation Support Specialist',\n",
       " 'Healthcare Recruiter',\n",
       " 'Mortgage Loan Officer',\n",
       " 'Founding Front-End Engineer (Web)',\n",
       " 'Design Engineer (Stellantis Background)',\n",
       " 'Heavy Equipment Mechanic',\n",
       " 'Shop Supervisor',\n",
       " 'Senior Communications and Development Manager',\n",
       " 'Sales Consultant (Outside Sales)',\n",
       " 'Principal Backend Engineer',\n",
       " 'Sales and Marketing Assistant (Graduate)',\n",
       " 'Loyalty Content Writer & Operations Manager',\n",
       " '2 Way Radio Installer',\n",
       " 'tester',\n",
       " 'Co-Founder',\n",
       " 'Director of Technical Operations',\n",
       " 'Wafer Process Engineer - Laser diode Chip Fabrication',\n",
       " 'Associate Attorney - Commercial Litigation',\n",
       " 'Program Manager',\n",
       " 'Nurse Injector',\n",
       " 'Primary Care Nurse Practitioner / Physician Assistant',\n",
       " 'Fractional CFO',\n",
       " 'Distributor Sales Specialist',\n",
       " 'Outside Salesperson',\n",
       " 'House Coordinator',\n",
       " 'Sr Data Engineer with Kafka',\n",
       " 'Unpaid Internship: Development Team',\n",
       " 'Swiss Setup Operator',\n",
       " 'Chairperson',\n",
       " 'Manager of Human Resources',\n",
       " 'People Manager or Workplace Counselor',\n",
       " 'Electrician Mechanic',\n",
       " '2+ years Attorney',\n",
       " 'Social Media Manager',\n",
       " 'Electronics Technician: Production, Service and Testing',\n",
       " 'Real Estate Agent',\n",
       " 'Care Coordinator',\n",
       " 'Founding High School Science Teacher',\n",
       " 'Field Sales Representative',\n",
       " 'Help Desk Analyst',\n",
       " 'Research Technician',\n",
       " 'Youth Coach',\n",
       " 'Freelance',\n",
       " 'Clinical Manager - RN',\n",
       " 'Nurse Practitioner',\n",
       " 'Records Specialist & Academic Scheduler',\n",
       " 'Community Association Manager- Portfolio',\n",
       " 'Wellness Associate',\n",
       " 'Accountant',\n",
       " 'Technician',\n",
       " 'Veterinary Technician Manager',\n",
       " 'Resolution Analyst',\n",
       " 'Commercial Loan Officer',\n",
       " 'Product Support Specialist',\n",
       " 'Creative Development Intern',\n",
       " 'THEATRE Instructor for Speech Communication & Theatre Department',\n",
       " 'Booking Producer',\n",
       " 'Family Physician',\n",
       " 'Registered Nurse RN - Medical ICU MICU - PT Nights',\n",
       " 'Assistant Buyer / Receiving',\n",
       " 'Mechanical Design Engineering Manager',\n",
       " 'Technical Business Analyst',\n",
       " 'Commercial Appraiser Manager',\n",
       " 'Senior Linux/RedHat Engineer',\n",
       " 'Content Manager (INTERNSHIP)',\n",
       " 'Upper School Mathematics Teacher',\n",
       " 'Project Estimator',\n",
       " 'Psychotherapist in Private Practice',\n",
       " 'Artificial Intelligence Engineer Intern - Chatbot',\n",
       " 'Science Teacher',\n",
       " 'Staff Engineer (Geotechnical, Geological or Mining)',\n",
       " 'Physical Therapist Tech',\n",
       " 'Speech Language Pathologist',\n",
       " 'Real Estate Sales Agent',\n",
       " 'Associate Director of Individual Giving',\n",
       " 'Building Maintenance Manager',\n",
       " 'Veterinarian',\n",
       " 'Armed Security Guard',\n",
       " 'Senior Account Executive',\n",
       " 'Bench Store Manager',\n",
       " 'Customer Service Specialist',\n",
       " 'Financial Advisor',\n",
       " 'Creative and Social Intern',\n",
       " 'Receptionist/Data Entry',\n",
       " 'Sales Business Development Executive',\n",
       " 'Social Media Marketing Intern',\n",
       " 'Brand Ambassador/Local Market Expert',\n",
       " 'Entry-Level Ecologist',\n",
       " 'Engineers / Marketing / Various',\n",
       " 'backend Java developer',\n",
       " 'Personal Assistant to Controller',\n",
       " 'Field Office ISSM - Open Rank-RS-Albuquerque, NM',\n",
       " 'Logistics Specialist',\n",
       " 'Cloud Platform/ Big Data Engineer',\n",
       " 'Assistant Landscape Architect',\n",
       " 'VP Ecommerce',\n",
       " 'Senior Staffing Specialist',\n",
       " 'Sales And Marketing Specialist',\n",
       " 'Program Associate',\n",
       " 'Data Science Software Engineer',\n",
       " 'Data Engineer/ETL',\n",
       " 'Hiring a Contract Lawyer with Probate Experience',\n",
       " 'Email Copywriter',\n",
       " 'Claim Manager',\n",
       " 'Mobile Application Developer',\n",
       " 'Flight Software Engineer',\n",
       " 'Financial Services Representative',\n",
       " 'BI Reporting Lead',\n",
       " 'Journeyman Electrician',\n",
       " 'Investor Relations Associate',\n",
       " 'Literature Review Panel Member',\n",
       " 'Commercial Real Estate Broker',\n",
       " 'Electrical Hardware Engineer',\n",
       " 'Marketing Intern',\n",
       " 'Superintendent (High-End Tenant Interiors)',\n",
       " 'Videographer Intern',\n",
       " 'Contract Licensed Clinical or Counseling Psychologist',\n",
       " 'Marketing and Events Manager',\n",
       " 'Senior Director, Clinical Pharmacology & Quantitative Pharmacology (CPQP)- ADC',\n",
       " 'Social Media Account Coordinator',\n",
       " 'Data Analyst',\n",
       " 'Quantitative Researcher - Semi-Systematic Credit',\n",
       " 'Dispensary Owner',\n",
       " 'MultiMedia Art Director',\n",
       " 'Business Development Representative',\n",
       " 'Generalist - Third-Party Logistics',\n",
       " 'Event Coordinator',\n",
       " 'Legal Assistant Paralegal',\n",
       " 'Purchasing Coordinator',\n",
       " 'Search Engine Optimization Specialist',\n",
       " 'Staff Software Engineer (AHT)',\n",
       " 'Accounting Manager',\n",
       " 'Investment Real Estate Sales Advisor',\n",
       " 'Marina Director',\n",
       " 'Deputy City Manager - Chief Financial Officer',\n",
       " 'Saxophone Repair Technician',\n",
       " 'Neighborhood Building Housing Leader',\n",
       " 'Freight Broker',\n",
       " 'SAFe Program Consultant (SPC)',\n",
       " 'Branch Manager',\n",
       " 'Head of Accounting',\n",
       " 'Client Solutions Manager - South Bay',\n",
       " 'Volunteer Child Care',\n",
       " 'Writing/Reading Tutor',\n",
       " 'Sales Associate',\n",
       " 'FL Bar Associate Attorney Tax, Trusts, and Estates',\n",
       " 'Service Specialist',\n",
       " 'Estimator - Commercial Construction',\n",
       " 'Traffic Coordinator/Scheduler',\n",
       " 'Account Coordinator',\n",
       " 'Registered Dental Hygienist',\n",
       " 'Police Officer',\n",
       " 'Product Designer',\n",
       " 'Labor And Employment Attorney',\n",
       " 'Entry Level Financial Professional',\n",
       " 'Financial Planning Specialist',\n",
       " 'Lead Dotnet Developer',\n",
       " 'Clinical Program Supervisor',\n",
       " 'Sr. Electrical Engineer',\n",
       " 'Social Media Manager/Specialist',\n",
       " 'Associate Veterinarian',\n",
       " 'VP of Engineering',\n",
       " 'Real Estate Broker Associate',\n",
       " 'Financial Reporting Senior Specialist',\n",
       " 'Field Service Technician (Residential ESS)',\n",
       " 'Electrical Engineering Intern',\n",
       " 'Sales Specialist',\n",
       " 'Medical Device Sales Specialist Intern',\n",
       " 'Senior Labor & Employment Attorney ',\n",
       " 'Pool Design and Sales Representative',\n",
       " 'Upper/Middle School Spanish and French Teacher Episcopal School of Acadiana',\n",
       " 'Sales Executive',\n",
       " 'Bilingual Counselor Advocate (Spanish-English)',\n",
       " 'Resource Development Associate Director',\n",
       " 'Entry Level Esthetician',\n",
       " 'üöÄ Join Our Team as a Senior iOS Developer at ABHI IT SYSTEMS INC üåê üöÄ',\n",
       " 'Marketing Coordinator / Graphics Specialist',\n",
       " 'Technical Designer',\n",
       " 'Decedent Affairs Coordinator',\n",
       " 'Property Manager',\n",
       " 'Operations Manager',\n",
       " 'Program Training Lead',\n",
       " 'Mentorship Case Manager',\n",
       " 'Mid-Level Project Electrical Engineer / Lighting Designer',\n",
       " 'Controls Engineer',\n",
       " 'Head of Sales',\n",
       " 'Physical Therapist Assistant',\n",
       " 'Design Consultant, Nashville, TN',\n",
       " 'Senior Accountant - Non Profit',\n",
       " 'Mid-Market Account Executive',\n",
       " 'Music Therapist',\n",
       " 'Associate Marketing Manager',\n",
       " 'Pilot in Command Phenom 300',\n",
       " 'Wholesale Sales Director, Luxury Fashion Accessories Company',\n",
       " 'Account Executive',\n",
       " 'CNC MACHINSITS NEEDED',\n",
       " 'Vice President Operations',\n",
       " 'SAP EWM Consultant',\n",
       " 'Print Traffic',\n",
       " 'Senior Landman',\n",
       " 'Senior Salesforce Developer',\n",
       " 'Revenue Cycle Specialist',\n",
       " 'Instructional Coach - Elementary',\n",
       " 'Manager - Accounts and Publishers',\n",
       " 'Chief Development Officer',\n",
       " 'Senior Cost Accountant',\n",
       " 'Senior Data Engineer/Analyst - Full Time',\n",
       " 'Registered Client Service Associate',\n",
       " 'Warehouse Associate',\n",
       " 'Frontend Engineer',\n",
       " 'Dentist',\n",
       " 'Human Resources Information System Specialist',\n",
       " 'Oracle P2P Analyst',\n",
       " 'PeopleSoft FSCM Functional Analyst - GL and KK modules',\n",
       " 'ABA Therapist/Special Education Paraprofessional - Various locations!',\n",
       " 'Internet Entrepeneur',\n",
       " 'Electrical Engineer',\n",
       " 'Sales Engineer',\n",
       " 'Real Estate Rental Manager',\n",
       " 'Junior Business Analyst',\n",
       " 'Cloud / .NET Developer',\n",
       " 'Associate - Job #1868',\n",
       " 'Stewardship Program Coordinator',\n",
       " 'General Manager',\n",
       " 'Cleaner',\n",
       " 'Insurance Agent',\n",
       " 'Administrative Assistant/Receptionist',\n",
       " 'Service Technician',\n",
       " 'Registered Behavior Technician ',\n",
       " 'Progressive Care Nurse',\n",
       " 'Campaigns Director',\n",
       " 'Line Cook - Mercantile Dining & Provision - DEN Airport',\n",
       " 'Data Processor',\n",
       " 'UX/Content Strategist',\n",
       " 'Claims Technician',\n",
       " 'Senior Business Application Developer',\n",
       " 'Collections Operator in Training',\n",
       " 'Senior Machine Learning Research Engineer',\n",
       " 'Senior SAP SD OTC Lead',\n",
       " 'Physical Therapist',\n",
       " 'Inside Sales Representative Custom Soccer Apparel',\n",
       " 'Pre-Finish Supervisor',\n",
       " 'Healthcare Call Center',\n",
       " 'Audiovisual Field Engineer',\n",
       " 'Senior Transportation Planner',\n",
       " 'Restaurant Manager',\n",
       " 'IT Support Specialist',\n",
       " 'Design Center Coordinator',\n",
       " 'Landscape Construction Business Developer',\n",
       " 'Social Media Coordinator(Monitor and Engage)-Part Time',\n",
       " '3D Scanning Specialist Account Manager',\n",
       " 'Freight Agent / Broker',\n",
       " 'Licensed Loan Partner',\n",
       " 'Quality process analyst | Hybrid in West Berlin, NJ',\n",
       " 'Business Development Account Manager',\n",
       " 'Professional Singer',\n",
       " 'Accounting Supervisor',\n",
       " 'Commercial Real Estate Attorney',\n",
       " 'Associate',\n",
       " 'Head of Product',\n",
       " 'Clinical Manager - Med Surg, Surgical Oncology',\n",
       " 'Education Coordinator',\n",
       " 'Dotnet Developer',\n",
       " 'Customer Service Agent',\n",
       " 'Learning And Development Specialist',\n",
       " 'Sales Manager of Cutting Tools',\n",
       " 'Fleet Operations Specialist',\n",
       " 'Sr. Designer Healthcar & AP',\n",
       " 'Bilingual Front Desk Receptionist',\n",
       " 'Licensed Financial Professional',\n",
       " 'Vice President of Sales',\n",
       " 'Engineering And Maintenance Manager',\n",
       " 'Sales Account Executive',\n",
       " 'Java full Stack Engineer',\n",
       " 'Full stack Azure .Net',\n",
       " 'Researcher',\n",
       " 'DevOps Engineer',\n",
       " 'Talent Acquisition',\n",
       " 'Tax Preparer',\n",
       " 'Part-Time Medical Assistant/LPN',\n",
       " 'Major Gift Officer',\n",
       " 'Strategy Manager',\n",
       " 'Treatment Coordinator',\n",
       " 'Automotive Technician',\n",
       " 'Technical Business Analyst Local to Des Moines, Iowa',\n",
       " 'Support Manager - East Coast',\n",
       " 'Donor Engagement Coordinator',\n",
       " 'AS400 Developer',\n",
       " 'IAM Security Specialist',\n",
       " 'Marketing & Events Intern',\n",
       " 'Human Resources Generalist',\n",
       " 'Associate Immigration Attorney',\n",
       " 'Part Time Driver (Manheim)',\n",
       " 'People and Office Operations',\n",
       " 'Business Development Manager',\n",
       " 'Revenue Cycle and Reimbursement Director',\n",
       " 'Front Office Specialist',\n",
       " 'Member Services Manager',\n",
       " 'Product Manager',\n",
       " 'Client Relationship Manager',\n",
       " 'Technical Writer',\n",
       " 'Financial Professional',\n",
       " 'Construction Superintendent',\n",
       " 'Administrative Assistant Intern',\n",
       " 'Senior Mortgage Loan Officer',\n",
       " 'Construction Estimator',\n",
       " 'Learning Experience Designer/Developer II',\n",
       " 'DIRECTOR OF MARKETING',\n",
       " 'AOC Human Resources Project Manager',\n",
       " 'Maintenance Technician - Night Shift',\n",
       " 'Territory Sales Manager',\n",
       " 'Business Office Manager',\n",
       " 'Webmethods Developer',\n",
       " 'Exercise Physiologist',\n",
       " 'AWS Cloud Architect (W2 Only)',\n",
       " 'Software Engineer in Test Automation',\n",
       " 'Technical Planner',\n",
       " 'Lactation Consultant',\n",
       " 'Junior Engineer - [Full Remote]',\n",
       " 'Sustaining Engineer',\n",
       " 'Manufacturing and Test Engineer',\n",
       " 'Master Planner',\n",
       " 'Senior Accountant',\n",
       " 'Licensed Healthcare Insurance Agent - Work from Home',\n",
       " 'MSP Engineer Level 3',\n",
       " 'Senior Materials Manager',\n",
       " 'Meat Manager',\n",
       " 'Media Sales Executive',\n",
       " 'SPS-02 Shipping (Non-Fork Lift) - Glendale, AZ',\n",
       " 'Remote Business Development Associate',\n",
       " 'Public Relations Intern, Summer 2024',\n",
       " 'Azure Tech Lead',\n",
       " 'Life Coach - Birmingham Campus',\n",
       " '100% commission Marketers for TV Doc \"The 40 Parables\"',\n",
       " 'Senior Windows System Administrator',\n",
       " 'Medical Doctor',\n",
       " 'Assistant Manager',\n",
       " 'Automation Specialist',\n",
       " 'Medical Laboratory Technician',\n",
       " 'Law Firm Administrator',\n",
       " 'Tech Sales Associate',\n",
       " 'Licensed Health Insurance Agent- Work from Home',\n",
       " 'Retail Sales Associate - Self Serve',\n",
       " 'Community Support Specialist',\n",
       " 'Inside Sales/Customer Service',\n",
       " 'Associate Director of Campus Safety',\n",
       " 'Senior Design Engineer/Project Manager',\n",
       " 'Client Support Specialist, Weekend Full-Time',\n",
       " 'Business Development Specialist',\n",
       " 'Tier One Customer Service Representative',\n",
       " '.Net Azure Architect (Local to WA)',\n",
       " 'Phone Triage (RN or LPN)',\n",
       " 'Bookkeeper',\n",
       " 'Graphic Designer',\n",
       " 'Sr. Project Engineer',\n",
       " 'SAP FICO ‚Äì AMS Consultant',\n",
       " 'Admissions Representative',\n",
       " 'Laboratory Technician',\n",
       " 'Android Developer Intern (Unpaid)',\n",
       " 'Merchandise Planner',\n",
       " 'Investor Service & Financial Planning Associate',\n",
       " 'Development Director',\n",
       " 'Head of Client Relations',\n",
       " 'Customer Service Representative 1 (Promo Roll)',\n",
       " 'Machine Learning Engineer',\n",
       " 'Server',\n",
       " '‚Ä¢\\tTier I Help Desk associate',\n",
       " 'Head of Content / Search Engine Optimization Copywriter',\n",
       " 'Community Engagement Coordinator',\n",
       " 'Land Use Planner / Entitlements Director',\n",
       " 'eCommerce Data Analyst',\n",
       " 'Cleaning Personnel',\n",
       " 'RE: Urgent hiring for Workday Prism Developer',\n",
       " 'Senior Commercial HVAC Estimator',\n",
       " 'Clinical Revenue Supervisor',\n",
       " 'Office Price Book Administrator',\n",
       " 'NAI / NAII - 2 South Medical- Surgical/Telemetry',\n",
       " 'Payroll Bookkeeper',\n",
       " 'Recruitment business development VP',\n",
       " 'Maintenance Technician',\n",
       " 'Level II Technicians and Assistants (preferably with radiation safety)',\n",
       " 'Security Professional',\n",
       " 'Medical Equipment Outside Sales Representative ',\n",
       " 'EV/Cash Flow Analyst',\n",
       " 'Front of House',\n",
       " 'Lead Product Designer',\n",
       " 'Partner Success Manager- Bilingual Spanish Speaker',\n",
       " 'Instructional Aide',\n",
       " 'Therapist',\n",
       " 'Chief Revenue Officer',\n",
       " 'Informatica MDM',\n",
       " 'Licensed Property & Casualty Insurance Agent',\n",
       " 'Integrated Marketing Manager',\n",
       " 'Education Budget Manager ',\n",
       " 'Precast Design Engineer',\n",
       " 'Staff Attorney - Housing',\n",
       " 'Maintenance Engineering specialist',\n",
       " 'Part-Time CFO/Controller',\n",
       " 'Help Desk Support',\n",
       " 'UNPAID Public Relations',\n",
       " 'M365 Architect',\n",
       " 'Medical Case Manager',\n",
       " 'Financial Accounting Specialist',\n",
       " 'Hiring for the role of Azure Cloud Engineer',\n",
       " 'Restaurant Shift Supervisor',\n",
       " 'Shelter Team Member with emphasis in Customer Care',\n",
       " 'Resident Engineer',\n",
       " 'Acoustic Consultant',\n",
       " 'Technology Trust & Compliance Professional',\n",
       " 'Sr Software Engineer',\n",
       " 'Radio Frequency Engineer',\n",
       " 'Hardware Design Engineer',\n",
       " 'Software Development Engineer in Test',\n",
       " 'Data Entry Specialist',\n",
       " 'Geographic Information System Specialist',\n",
       " 'Desktop Support Technician',\n",
       " 'Remodeling/Insurance Estimator',\n",
       " 'service now architect',\n",
       " 'Manager, Conference Operations',\n",
       " 'Upholsterer',\n",
       " 'Director of Project Management (ecological restoration)',\n",
       " 'Engineering Project Manager / Project Manager',\n",
       " 'Associate Compliance Officer and Director of International Affairs Compliance',\n",
       " 'Call Center Representative',\n",
       " 'M365 Power-Platform or SharePoint Online Developer',\n",
       " 'Research Associate (Scientific Communications)',\n",
       " 'Dialysis Technician',\n",
       " 'Senior Lawyer',\n",
       " 'Battery R&D Scientist',\n",
       " 'Sales Director',\n",
       " 'Pediatric Occupational Therapist',\n",
       " 'Accounts Payable Associate',\n",
       " 'Marketing Specialist - Membership Growth & Retention',\n",
       " 'Lead Documentum Consultant',\n",
       " 'IT Project Manager (Remote Work Available)',\n",
       " 'Content Creator/Videographer Role',\n",
       " 'Product Validation Engineer (EVT/DVT)\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t',\n",
       " 'Service Supervisor',\n",
       " 'Wholesale Sales Assistant',\n",
       " 'Construction Accountant',\n",
       " 'Regional Sales Manager',\n",
       " 'MicroStrategy Administrator',\n",
       " 'Watchmaker',\n",
       " 'Head of Client Services',\n",
       " 'Clinical Appeals Manager (RN)',\n",
       " 'CRA Officer (Community Reinvestment Officer)',\n",
       " 'Operational Meteorologist',\n",
       " 'Technical Product Manager - Cloud',\n",
       " 'Personal Lines Account Executive',\n",
       " 'Financial Operations & Decision Support Manager',\n",
       " 'Structural Design Engineer',\n",
       " 'PRN Registered Nurse',\n",
       " 'ComEd - Maint Mech 0 Cert Fleet',\n",
       " 'Sales and Leasing Consultant',\n",
       " 'Manager, Corporate Vertical Sales',\n",
       " 'Azure Data Engineer (Full time)',\n",
       " 'Heat Treat Operator',\n",
       " 'Research Associate (Molecular Biology & Protein Expression)',\n",
       " 'PR Editor and Proofreader',\n",
       " 'Dir / Sr Dir SaaS Development',\n",
       " 'Procurement Specialist',\n",
       " 'Senior Brand Manager - Campaigns',\n",
       " 'Payroll & HRIS Administrator',\n",
       " 'Maintenance Tech 12A - 2nd Shift',\n",
       " 'Manufacturing Engineer',\n",
       " 'Accounts Receivable Analyst',\n",
       " 'Regional Technical Specialist',\n",
       " 'Machining - Grinding Specialist',\n",
       " 'CNC Machine Operator 3rd shift',\n",
       " 'Product Marketing Specialist',\n",
       " 'Digital Analyst (Google Analytics)',\n",
       " 'Field Sales Consultant',\n",
       " 'Homeless Shelter Manager- La Posada',\n",
       " 'Sales and Customer Experience Specialist',\n",
       " 'Public Relations Intern',\n",
       " 'Federal Grant and Assessment Director',\n",
       " 'Machine Operator',\n",
       " 'Seal Product Design Engineer',\n",
       " 'Manufacturing Systems Coordinator',\n",
       " 'Assistant Controller',\n",
       " 'Application Engineer',\n",
       " 'Heat Treat Manager',\n",
       " 'Demand Planner',\n",
       " 'Pool Remodel Salesman',\n",
       " 'Information Technology Manager',\n",
       " 'Sociology Research & Writing Intern',\n",
       " 'CNC Machinist',\n",
       " 'Manufacturing Engineering Manager',\n",
       " 'CH 18 Machine Operator - 2nd Shift',\n",
       " 'Commercial Lines Small Business Account Manager',\n",
       " 'Director, Finance Business Systems',\n",
       " 'Financial Advisor (Sales Role-Training Provided)',\n",
       " 'Senior Construction Manager',\n",
       " 'Human Resources Office Support Technician',\n",
       " 'Environmental Engineer',\n",
       " 'Mutual Fund Financial Reporting Analyst',\n",
       " 'Store Manager',\n",
       " 'Regional Sales Manager - Northwest',\n",
       " 'Senior Scientific Project Manager - Genomics',\n",
       " 'Mortgage Loan Officer - Texas/Remote',\n",
       " 'Estimation Engineer',\n",
       " 'Billing Specialist',\n",
       " 'W2 only _ Java Developer',\n",
       " 'Real Estate Office Assistant',\n",
       " 'Superintendent',\n",
       " 'Communications Intern',\n",
       " 'Cyber security /Report Developer ( W2 Role)',\n",
       " 'New Business Development Representative',\n",
       " '416550 - Postdoctoral Appointee - CSE - Heavy Element Chemistry and Separation Science Group',\n",
       " 'RN - Pre-op and PACU 0.9 FTE Day',\n",
       " 'Area Sales Manager',\n",
       " 'Summer Law Clerk',\n",
       " 'Refugee Medical Assistant',\n",
       " '2024-2025 Project Facilitator, Special Education',\n",
       " 'Senior Business Analyst (Pharma/Biotech/Scientific)',\n",
       " 'SAP Partner - Account Management',\n",
       " 'Logistics Operations Engineer',\n",
       " 'Employment & HR Litigation Attorney',\n",
       " 'Interim DON',\n",
       " 'Legal Assistant (Legal Access Officer)',\n",
       " 'Senior Project Manager - GC',\n",
       " 'Environmental Protection Specialist',\n",
       " 'Manager Technology ',\n",
       " 'Fleet Manager',\n",
       " 'Internet of Things Engineer',\n",
       " 'Technical Project Manager/Scrum Master',\n",
       " 'Patient Access Associate II',\n",
       " 'Electrical and Instrumentation Technician',\n",
       " 'Mental Health Professional - $3,000 Hiring Bonus',\n",
       " 'Retail, Sales Associate',\n",
       " 'Senior Robotics Engineer (Commercial Grade)',\n",
       " 'Inventory Control Associate - 1st Shift',\n",
       " 'Java Technical Lead',\n",
       " 'Assistant Principal - Jydstrup ES',\n",
       " 'Senior Automation Engineer',\n",
       " 'Personal Lines Account Manager',\n",
       " 'Early Childhood Associate 2024-25 School Year',\n",
       " 'Bilingual Sales Assistant',\n",
       " 'New Home Sales Director (Relocatable)',\n",
       " 'Enterprise Account Executive - Pacific North West (SLED)',\n",
       " 'AVP, Underwriting Team Leader | Hybrid',\n",
       " 'Commercial CSR (trucking)',\n",
       " 'Convention Sales and Business Development Manager',\n",
       " 'Customer Advocacy Manager',\n",
       " 'Graphic and Website Design Specialist',\n",
       " 'Reliability/Injection Molding Maintenance Technician',\n",
       " 'Guest Experience Specialist',\n",
       " 'Rehab Therapy Manager',\n",
       " 'Store Experience Guide ‚Äì Part Time ‚Äì Carlsbad',\n",
       " 'Communication and Change Manager',\n",
       " 'Metallurgist',\n",
       " 'Visual Inspector',\n",
       " 'General Operator 3rd Shift',\n",
       " 'Business Controlling, Full Value Chain Americas',\n",
       " 'Quality Inspector',\n",
       " 'Sales Administrative Assistant',\n",
       " 'Java Architect',\n",
       " 'Construction Manager',\n",
       " 'Human Resources Transactions Manager',\n",
       " 'Database Administrator (BOCA RATON)',\n",
       " 'Staff / Senior Accountant (',\n",
       " 'Digital Designer',\n",
       " 'Part time Recruiter',\n",
       " 'Laboratory Coordinator',\n",
       " 'Data Management Analyst',\n",
       " 'Electrical and Instrumentation Engineer',\n",
       " 'Vice President, HR, Associate Experience ',\n",
       " 'Certified Medical Assistant',\n",
       " 'Director of Economic Development',\n",
       " 'Distribution/Warehousing Support Manager',\n",
       " 'Field Service Technician',\n",
       " 'Timekeeper',\n",
       " 'Medical Claims Processor',\n",
       " 'Software Engineer with Vue JS.',\n",
       " 'Police Records Specialist',\n",
       " '2024-2025 GENERAL RESOURCE TEACHER - NEVADA LEARNING ACADEMY',\n",
       " 'Sr. Project Analyst - Value Management (Hospital & Healthcare)',\n",
       " 'Senior Sales Manager - Renaissance Harlem ',\n",
       " 'Patient Coordinator',\n",
       " 'Office Administrator',\n",
       " 'Maintenance Tech for Luxury Property',\n",
       " 'Director of Childhood Education ',\n",
       " 'Sr. Director, Media Communications Planning',\n",
       " 'Senior Business Analyst',\n",
       " 'Quality Control Specialist',\n",
       " 'CHIEF OF STAFF',\n",
       " 'Quality Assurance Specialist - DRUG (Pharma/Biotech/Medical Devices) - Frederick, MD/Wilson, NC',\n",
       " 'Chemist I ',\n",
       " 'Junior Project Manager',\n",
       " 'Facility Engineer',\n",
       " 'Foreperson, Commuter Rail',\n",
       " 'Medical Coder',\n",
       " 'Assistant, Management (Labor Supply and Partnerships) - 516461',\n",
       " 'Commercial Insurance Placement Specialist - Hybrid Remote',\n",
       " 'Commercial Insurance Account Assistant - Hybrid',\n",
       " 'Pediatric Dietitian I - Cardiac Transplant / Cardiology',\n",
       " 'Principal Systems Engineer',\n",
       " 'Insurance ‚Äì Personal Lines - DC12731',\n",
       " 'Cloud DevOps Engineer',\n",
       " 'Senior Analyst, Data & Analytics',\n",
       " 'Call Center-REMOTE',\n",
       " 'Search Engine Optimization Manager',\n",
       " 'Computer Field Service Technician ',\n",
       " 'FT Relationship Banker I or II',\n",
       " 'SKILL DEVELOPMENT COORDINATOR',\n",
       " 'SRE/DevOps Support Engineer (W2)',\n",
       " 'CNC Operator 2nd Shift',\n",
       " 'Operational Buyer, Vehicle Aftermarket',\n",
       " 'Millwright Journeyman',\n",
       " 'VP of Digital Enablement and Technology',\n",
       " 'Industrial Maintenance Technician',\n",
       " 'Procurement Quality Engineer',\n",
       " 'People Experience Expert Level II',\n",
       " 'Mine Foreman',\n",
       " 'Project Management Director',\n",
       " 'Associate Accountant, Payroll Tax ',\n",
       " 'Senior HR Generalist',\n",
       " 'Digital Asset Management Specialist ',\n",
       " 'Maintenance Supervisor (Signals) II (Instructor)',\n",
       " 'Promotions Manager',\n",
       " 'Tax Supervisor',\n",
       " 'ServiceNow Developer',\n",
       " 'Information Security Manager',\n",
       " 'Primary Care Physician',\n",
       " 'Senior Developer ‚Äì React Native',\n",
       " 'Driver',\n",
       " 'Sales Development Representative (SDR)',\n",
       " 'Azure Data Engineer',\n",
       " 'Private Equity Analyst',\n",
       " 'Creative Content Developer (323565)',\n",
       " 'Quality Technician',\n",
       " 'Senior Front-End Engineer ',\n",
       " 'Accounts Payable Clerk - Temp to Hire',\n",
       " 'Banking Operations Systems Analyst',\n",
       " 'System Administrator with HCP & AWS',\n",
       " 'Rental Linen & Uniform Sales',\n",
       " 'Financial Director',\n",
       " 'Software Design Engineer',\n",
       " 'Payroll/HR Associate (Pharma/Biotech/Med Devices/Healthcare) - Hybrid!!',\n",
       " 'Principal Engineer- Water Department',\n",
       " 'Attorneys - Business,Real Estate,Land Use and Estate Planning',\n",
       " 'Universal Banker ',\n",
       " 'Senior Director, Epidemiology (REMOTE 100%)',\n",
       " 'Security Engineer',\n",
       " '2024-2025 Humanities Teacher - Cox, Clyde ES',\n",
       " 'Clerk 1/ Community Service Aide',\n",
       " 'Insurance Account Manager - New Haven CT',\n",
       " 'Secretary (Unit Secretary)',\n",
       " ' Junior ETL QA Test Engineer',\n",
       " 'Respiratory Care Practitioner',\n",
       " 'Paper Converting Machine Operator',\n",
       " 'Civil Engineering - Utilities & Public Works Project Manager',\n",
       " 'Senior Investigator/Tester/Teacher',\n",
       " 'Fulltime RN - TheraCare Home Health Houston',\n",
       " 'Sr. Business Analyst/Tester',\n",
       " 'Associate Director of Events',\n",
       " 'Instructional Coach',\n",
       " 'Work Based Learning Coordinator',\n",
       " 'Sales Assistant (Full-Time)',\n",
       " 'Renewal Manager',\n",
       " 'Training Program Manager',\n",
       " 'Utilities Mechanic - HVAC - JW',\n",
       " \"Commercial Lines Account Manager - Workers' Compensation\",\n",
       " 'Director, Global Compliance',\n",
       " 'Clinical Pharmacist - OP',\n",
       " 'Dispatch Coordinator',\n",
       " 'Medical Office Technician - RMA/CMA/CCMA',\n",
       " 'Wastewater EIT',\n",
       " 'Assistant Claims Examiner (Onsite Atlanta GA.)',\n",
       " 'Labor and Delivery - RN',\n",
       " 'Fabricator',\n",
       " 'IT QA Engineer II',\n",
       " 'Test Engineer',\n",
       " 'Quality Supervisor',\n",
       " 'CH 9 Machine Operator 2nd Shift',\n",
       " 'Human Resource Administrator',\n",
       " 'Fluorescent Penetrant Inspector',\n",
       " 'Global Graduate, Aerospace',\n",
       " 'Knowledge Digitalization Engineer',\n",
       " 'Reliability Program Lead',\n",
       " 'Human Resource Manager',\n",
       " 'Sales Supervisor - Lido Marina Village',\n",
       " 'Risk Consultant',\n",
       " 'Windows Software Engineer',\n",
       " 'SAP S/4 Cloud Delivery Lead (Automotive Car Motor/Vehicle Manufacturing experience) ',\n",
       " 'Electrical & Instrumentation Inspectors - Contract',\n",
       " 'Payroll and Benefits Specialist',\n",
       " 'HRIS & People Data Administrator',\n",
       " 'Office Assistant',\n",
       " 'Fair Lending Compliance Analyst',\n",
       " 'Opera Cloud PM',\n",
       " 'Wealth Management Business Data Analyst',\n",
       " 'Senior Dotnet Developer',\n",
       " 'Bilingual Staff Attorney, Farmworker Program',\n",
       " 'Executive Assistant to Chief Executive Officer',\n",
       " 'Treasury Manager',\n",
       " 'Manager, Talent and Organizational Development',\n",
       " 'Group Benefits Account Manager',\n",
       " ' Sr Import/Export Analyst ',\n",
       " 'Exam Proctor',\n",
       " 'IT Service Desk Specialist I',\n",
       " '2024-2025 MATH TEACHER HS - LAS VEGAS HS',\n",
       " '2024-2025 Physical Science Teacher - CLARK HS',\n",
       " 'Senior ReactJS Developer',\n",
       " 'Dental Assistant-Oral Surgery/Endo/General Anesthesia',\n",
       " 'Formulations & Material Handling Team Leader',\n",
       " 'Clinical Contracts Manager (Seattle/Santa Monica/Parsippany/Foster City)',\n",
       " 'Senior ELK Admin',\n",
       " 'Financial Analyst',\n",
       " 'Biopharmaceutical Manufacturing Production Specialist',\n",
       " 'Associate Communications Specialist - Transit Control Center',\n",
       " 'Program/Site Director I',\n",
       " 'Cook',\n",
       " 'Renewable Energy Administrative Data Coordinator',\n",
       " 'Operations Excellence Leader',\n",
       " 'Full Manager Bookkeeper (26394)',\n",
       " 'Ultrasound Technologist ',\n",
       " 'Senior Staff Accountant (26391)',\n",
       " 'Electrical Engineer (Power Supply)',\n",
       " 'Corporate & Entrepreneurial Interviewer',\n",
       " 'Generative AI Engineer',\n",
       " 'Subrogation Services, Associate (Remote, USA)',\n",
       " 'Office Professional, R&D/TS&D',\n",
       " 'SBDC Business Consultant',\n",
       " 'Entry Level Account Manager ‚Äì Relocation Department',\n",
       " 'Store Loss Prevention Investigator',\n",
       " 'Site Warehouse Manager',\n",
       " 'Senior Project Manager',\n",
       " 'Vice President of Development',\n",
       " 'Accountant I Corporate Reporting',\n",
       " 'Information Technology Analyst II',\n",
       " 'Manager - Digital Marketing',\n",
       " 'Installation Engineer',\n",
       " 'Manager Project Engineering (HVAC / Construction))',\n",
       " 'Tailor/Patternmaker',\n",
       " 'Business Development Associate',\n",
       " 'Registered Nurse (Bronx | 24 Hours/Week | Part-Time)',\n",
       " 'Regulatory Submissions Manager_ Remote',\n",
       " 'Corporate Accountant',\n",
       " 'Process Engineer',\n",
       " 'Accounting and Finance Consulting Opportunities',\n",
       " 'Account Sales Executive- Fresno/ Clovis',\n",
       " '2024-2025 Grade 1 Teacher Goynes ES',\n",
       " 'Healthcare QA',\n",
       " 'Validation Analyst',\n",
       " 'Tibco Administrator with Azure DevOps Exp',\n",
       " 'Vice President of Marketing',\n",
       " 'Ruby on Rails Developer',\n",
       " 'Air Conditioning Equipment Mechanic Supervisor (HVAC Foreman)',\n",
       " 'Index Bond Pricing Analyst',\n",
       " 'Production Supervisor',\n",
       " 'Control Room Compliance Officer',\n",
       " 'Senior Architect',\n",
       " ...]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data['title'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b864070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title\n",
      "Project Manager                                        354\n",
      "Senior Software Engineer                               162\n",
      "Project Engineer                                       102\n",
      "Full Stack Engineer                                     57\n",
      "Web Developer                                           43\n",
      "Senior Business Analyst                                 34\n",
      "Data Architect                                          27\n",
      "Test Engineer                                           24\n",
      "Sr Software Engineer                                     6\n",
      "Cloud DevOps Engineer                                    3\n",
      "Senior Developer ‚Äì React Native                          3\n",
      "Software Implementation Program Manager                  2\n",
      "Computer Scientist                                       1\n",
      "Front end specialist                                     1\n",
      "Vice President - Engineering & Production Operation      1\n",
      "Java architect / Lead Java developer                     1\n",
      "Enterprise Data & Analytics Infrastructure Manager       1\n",
      "Sr. Business Analyst/Tester                              1\n",
      "IT QA Engineer II                                        1\n",
      "Senior Analyst, Data & Analytics                         1\n",
      "Java full Stack Engineer                                 1\n",
      "Engineering Project Manager / Project Manager            1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# List of titles to count\n",
    "titles_to_count = [\n",
    "    'Full Stack Engineer',\n",
    "    'Computer Scientist',\n",
    "    'Front end specialist',\n",
    "    'Project Engineer',\n",
    "    'Data Architect',\n",
    "    'Project Manager',\n",
    "    'Java architect / Lead Java developer',\n",
    "    'Enterprise Data & Analytics Infrastructure Manager',\n",
    "    'Senior Software Engineer',\n",
    "    'Web Developer',\n",
    "    'Software Implementation Program Manager',\n",
    "    'Vice President - Engineering & Production Operation',\n",
    "    'Test Engineer',\n",
    "    'Sr Software Engineer',\n",
    "    'IT QA Engineer II',\n",
    "    'Sr. Business Analyst/Tester',\n",
    "    'Senior Developer ‚Äì React Native',\n",
    "    'Cloud DevOps Engineer',\n",
    "    'Senior Analyst, Data & Analytics',\n",
    "    'Senior Business Analyst',\n",
    "    'Engineering Project Manager / Project Manager',\n",
    "    'Java full Stack Engineer'\n",
    "]\n",
    "\n",
    "# Count occurrences of each title\n",
    "title_counts = data['title'].value_counts()\n",
    "\n",
    "# Filter counts for the specified titles\n",
    "filtered_counts = title_counts[title_counts.index.isin(titles_to_count)]\n",
    "\n",
    "# Display the counts\n",
    "print(filtered_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d9a53fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset size: 123842 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ccee0_row0_col1, #T_ccee0_row1_col1, #T_ccee0_row2_col1, #T_ccee0_row3_col1, #T_ccee0_row4_col1, #T_ccee0_row5_col1, #T_ccee0_row6_col1, #T_ccee0_row7_col1, #T_ccee0_row8_col1, #T_ccee0_row9_col1, #T_ccee0_row10_col1, #T_ccee0_row11_col1 {\n",
       "  background-color: #00441b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ccee0_row0_col2, #T_ccee0_row1_col2, #T_ccee0_row2_col2, #T_ccee0_row3_col2, #T_ccee0_row4_col2, #T_ccee0_row5_col2, #T_ccee0_row6_col2, #T_ccee0_row7_col2, #T_ccee0_row8_col2, #T_ccee0_row9_col2, #T_ccee0_row10_col2, #T_ccee0_row11_col2 {\n",
       "  background-color: #7f2704;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ccee0_row0_col3, #T_ccee0_row1_col3, #T_ccee0_row2_col3, #T_ccee0_row3_col3, #T_ccee0_row4_col3, #T_ccee0_row5_col3, #T_ccee0_row6_col3, #T_ccee0_row7_col3, #T_ccee0_row8_col3, #T_ccee0_row9_col3, #T_ccee0_row10_col3, #T_ccee0_row11_col3 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ccee0_row12_col1, #T_ccee0_row13_col1, #T_ccee0_row14_col1 {\n",
       "  background-color: #00481d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ccee0_row12_col2, #T_ccee0_row13_col2, #T_ccee0_row14_col2 {\n",
       "  background-color: #832804;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ccee0_row12_col3, #T_ccee0_row13_col3, #T_ccee0_row14_col3 {\n",
       "  background-color: #6d010e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ccee0_row15_col1 {\n",
       "  background-color: #0c7735;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ccee0_row15_col2 {\n",
       "  background-color: #b83c02;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ccee0_row15_col3 {\n",
       "  background-color: #b21218;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ccee0_row16_col1 {\n",
       "  background-color: #1c8540;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ccee0_row16_col2 {\n",
       "  background-color: #ce4401;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ccee0_row16_col3 {\n",
       "  background-color: #c3161b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ccee0_row17_col1 {\n",
       "  background-color: #208843;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ccee0_row17_col2 {\n",
       "  background-color: #d54601;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ccee0_row17_col3 {\n",
       "  background-color: #c8171c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ccee0_row18_col1 {\n",
       "  background-color: #2f974e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ccee0_row18_col2 {\n",
       "  background-color: #e25508;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ccee0_row18_col3 {\n",
       "  background-color: #d92523;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ccee0_row19_col1 {\n",
       "  background-color: #359e53;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ccee0_row19_col2 {\n",
       "  background-color: #e75c0c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ccee0_row19_col3 {\n",
       "  background-color: #e12d26;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ccee0_row20_col1, #T_ccee0_row21_col1, #T_ccee0_row22_col1, #T_ccee0_row23_col1 {\n",
       "  background-color: #bde5b6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccee0_row20_col2, #T_ccee0_row21_col2, #T_ccee0_row22_col2, #T_ccee0_row23_col2 {\n",
       "  background-color: #fdc794;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccee0_row20_col3, #T_ccee0_row21_col3, #T_ccee0_row22_col3, #T_ccee0_row23_col3 {\n",
       "  background-color: #fcb095;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccee0_row24_col1, #T_ccee0_row25_col1 {\n",
       "  background-color: #cbebc5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccee0_row24_col2, #T_ccee0_row25_col2 {\n",
       "  background-color: #fdd3a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccee0_row24_col3, #T_ccee0_row25_col3 {\n",
       "  background-color: #fcc1a8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccee0_row26_col1 {\n",
       "  background-color: #d8f0d2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccee0_row26_col2 {\n",
       "  background-color: #fedcbb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccee0_row26_col3 {\n",
       "  background-color: #fdd0bc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccee0_row27_col1 {\n",
       "  background-color: #e7f6e2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccee0_row27_col2 {\n",
       "  background-color: #fee7d1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccee0_row27_col3 {\n",
       "  background-color: #fee2d5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccee0_row28_col1 {\n",
       "  background-color: #f1faee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccee0_row28_col2 {\n",
       "  background-color: #fff0e2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccee0_row28_col3 {\n",
       "  background-color: #ffeee7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccee0_row29_col1 {\n",
       "  background-color: #f6fcf4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccee0_row29_col2 {\n",
       "  background-color: #fff4e9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccee0_row29_col3 {\n",
       "  background-color: #fff4ee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccee0_row30_col1 {\n",
       "  background-color: #f7fcf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccee0_row30_col2 {\n",
       "  background-color: #fff5eb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccee0_row30_col3 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ccee0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ccee0_level0_col0\" class=\"col_heading level0 col0\" >column_name</th>\n",
       "      <th id=\"T_ccee0_level0_col1\" class=\"col_heading level0 col1\" >available_count</th>\n",
       "      <th id=\"T_ccee0_level0_col2\" class=\"col_heading level0 col2\" >missing_count</th>\n",
       "      <th id=\"T_ccee0_level0_col3\" class=\"col_heading level0 col3\" >missing_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ccee0_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ccee0_row0_col0\" class=\"data row0 col0\" >job_id</td>\n",
       "      <td id=\"T_ccee0_row0_col1\" class=\"data row0 col1\" >123842</td>\n",
       "      <td id=\"T_ccee0_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_ccee0_row0_col3\" class=\"data row0 col3\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccee0_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ccee0_row1_col0\" class=\"data row1 col0\" >work_type</td>\n",
       "      <td id=\"T_ccee0_row1_col1\" class=\"data row1 col1\" >123842</td>\n",
       "      <td id=\"T_ccee0_row1_col2\" class=\"data row1 col2\" >0</td>\n",
       "      <td id=\"T_ccee0_row1_col3\" class=\"data row1 col3\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccee0_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ccee0_row2_col0\" class=\"data row2 col0\" >sponsored</td>\n",
       "      <td id=\"T_ccee0_row2_col1\" class=\"data row2 col1\" >123842</td>\n",
       "      <td id=\"T_ccee0_row2_col2\" class=\"data row2 col2\" >0</td>\n",
       "      <td id=\"T_ccee0_row2_col3\" class=\"data row2 col3\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccee0_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_ccee0_row3_col0\" class=\"data row3 col0\" >listed_time</td>\n",
       "      <td id=\"T_ccee0_row3_col1\" class=\"data row3 col1\" >123842</td>\n",
       "      <td id=\"T_ccee0_row3_col2\" class=\"data row3 col2\" >0</td>\n",
       "      <td id=\"T_ccee0_row3_col3\" class=\"data row3 col3\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccee0_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_ccee0_row4_col0\" class=\"data row4 col0\" >expiry</td>\n",
       "      <td id=\"T_ccee0_row4_col1\" class=\"data row4 col1\" >123842</td>\n",
       "      <td id=\"T_ccee0_row4_col2\" class=\"data row4 col2\" >0</td>\n",
       "      <td id=\"T_ccee0_row4_col3\" class=\"data row4 col3\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccee0_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_ccee0_row5_col0\" class=\"data row5 col0\" >application_type</td>\n",
       "      <td id=\"T_ccee0_row5_col1\" class=\"data row5 col1\" >123842</td>\n",
       "      <td id=\"T_ccee0_row5_col2\" class=\"data row5 col2\" >0</td>\n",
       "      <td id=\"T_ccee0_row5_col3\" class=\"data row5 col3\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccee0_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_ccee0_row6_col0\" class=\"data row6 col0\" >original_listed_time</td>\n",
       "      <td id=\"T_ccee0_row6_col1\" class=\"data row6 col1\" >123842</td>\n",
       "      <td id=\"T_ccee0_row6_col2\" class=\"data row6 col2\" >0</td>\n",
       "      <td id=\"T_ccee0_row6_col3\" class=\"data row6 col3\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccee0_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_ccee0_row7_col0\" class=\"data row7 col0\" >formatted_work_type</td>\n",
       "      <td id=\"T_ccee0_row7_col1\" class=\"data row7 col1\" >123842</td>\n",
       "      <td id=\"T_ccee0_row7_col2\" class=\"data row7 col2\" >0</td>\n",
       "      <td id=\"T_ccee0_row7_col3\" class=\"data row7 col3\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccee0_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_ccee0_row8_col0\" class=\"data row8 col0\" >job_posting_url</td>\n",
       "      <td id=\"T_ccee0_row8_col1\" class=\"data row8 col1\" >123842</td>\n",
       "      <td id=\"T_ccee0_row8_col2\" class=\"data row8 col2\" >0</td>\n",
       "      <td id=\"T_ccee0_row8_col3\" class=\"data row8 col3\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccee0_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_ccee0_row9_col0\" class=\"data row9 col0\" >title</td>\n",
       "      <td id=\"T_ccee0_row9_col1\" class=\"data row9 col1\" >123842</td>\n",
       "      <td id=\"T_ccee0_row9_col2\" class=\"data row9 col2\" >0</td>\n",
       "      <td id=\"T_ccee0_row9_col3\" class=\"data row9 col3\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccee0_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_ccee0_row10_col0\" class=\"data row10 col0\" >location</td>\n",
       "      <td id=\"T_ccee0_row10_col1\" class=\"data row10 col1\" >123842</td>\n",
       "      <td id=\"T_ccee0_row10_col2\" class=\"data row10 col2\" >0</td>\n",
       "      <td id=\"T_ccee0_row10_col3\" class=\"data row10 col3\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccee0_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_ccee0_row11_col0\" class=\"data row11 col0\" >description</td>\n",
       "      <td id=\"T_ccee0_row11_col1\" class=\"data row11 col1\" >123842</td>\n",
       "      <td id=\"T_ccee0_row11_col2\" class=\"data row11 col2\" >0</td>\n",
       "      <td id=\"T_ccee0_row11_col3\" class=\"data row11 col3\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccee0_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_ccee0_row12_col0\" class=\"data row12 col0\" >views</td>\n",
       "      <td id=\"T_ccee0_row12_col1\" class=\"data row12 col1\" >122153</td>\n",
       "      <td id=\"T_ccee0_row12_col2\" class=\"data row12 col2\" >1689</td>\n",
       "      <td id=\"T_ccee0_row12_col3\" class=\"data row12 col3\" >1.36%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccee0_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_ccee0_row13_col0\" class=\"data row13 col0\" >company_id</td>\n",
       "      <td id=\"T_ccee0_row13_col1\" class=\"data row13 col1\" >122126</td>\n",
       "      <td id=\"T_ccee0_row13_col2\" class=\"data row13 col2\" >1716</td>\n",
       "      <td id=\"T_ccee0_row13_col3\" class=\"data row13 col3\" >1.39%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccee0_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_ccee0_row14_col0\" class=\"data row14 col0\" >company_name</td>\n",
       "      <td id=\"T_ccee0_row14_col1\" class=\"data row14 col1\" >122124</td>\n",
       "      <td id=\"T_ccee0_row14_col2\" class=\"data row14 col2\" >1718</td>\n",
       "      <td id=\"T_ccee0_row14_col3\" class=\"data row14 col3\" >1.39%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccee0_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_ccee0_row15_col0\" class=\"data row15 col0\" >zip_code</td>\n",
       "      <td id=\"T_ccee0_row15_col1\" class=\"data row15 col1\" >102974</td>\n",
       "      <td id=\"T_ccee0_row15_col2\" class=\"data row15 col2\" >20868</td>\n",
       "      <td id=\"T_ccee0_row15_col3\" class=\"data row15 col3\" >16.85%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccee0_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_ccee0_row16_col0\" class=\"data row16 col0\" >fips</td>\n",
       "      <td id=\"T_ccee0_row16_col1\" class=\"data row16 col1\" >96431</td>\n",
       "      <td id=\"T_ccee0_row16_col2\" class=\"data row16 col2\" >27411</td>\n",
       "      <td id=\"T_ccee0_row16_col3\" class=\"data row16 col3\" >22.13%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccee0_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_ccee0_row17_col0\" class=\"data row17 col0\" >formatted_experience_level</td>\n",
       "      <td id=\"T_ccee0_row17_col1\" class=\"data row17 col1\" >94440</td>\n",
       "      <td id=\"T_ccee0_row17_col2\" class=\"data row17 col2\" >29402</td>\n",
       "      <td id=\"T_ccee0_row17_col3\" class=\"data row17 col3\" >23.74%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccee0_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_ccee0_row18_col0\" class=\"data row18 col0\" >application_url</td>\n",
       "      <td id=\"T_ccee0_row18_col1\" class=\"data row18 col1\" >87184</td>\n",
       "      <td id=\"T_ccee0_row18_col2\" class=\"data row18 col2\" >36658</td>\n",
       "      <td id=\"T_ccee0_row18_col3\" class=\"data row18 col3\" >29.60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccee0_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_ccee0_row19_col0\" class=\"data row19 col0\" >posting_domain</td>\n",
       "      <td id=\"T_ccee0_row19_col1\" class=\"data row19 col1\" >83881</td>\n",
       "      <td id=\"T_ccee0_row19_col2\" class=\"data row19 col2\" >39961</td>\n",
       "      <td id=\"T_ccee0_row19_col3\" class=\"data row19 col3\" >32.27%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccee0_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_ccee0_row20_col0\" class=\"data row20 col0\" >normalized_salary</td>\n",
       "      <td id=\"T_ccee0_row20_col1\" class=\"data row20 col1\" >36072</td>\n",
       "      <td id=\"T_ccee0_row20_col2\" class=\"data row20 col2\" >87770</td>\n",
       "      <td id=\"T_ccee0_row20_col3\" class=\"data row20 col3\" >70.87%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccee0_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_ccee0_row21_col0\" class=\"data row21 col0\" >compensation_type</td>\n",
       "      <td id=\"T_ccee0_row21_col1\" class=\"data row21 col1\" >36072</td>\n",
       "      <td id=\"T_ccee0_row21_col2\" class=\"data row21 col2\" >87770</td>\n",
       "      <td id=\"T_ccee0_row21_col3\" class=\"data row21 col3\" >70.87%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccee0_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_ccee0_row22_col0\" class=\"data row22 col0\" >pay_period</td>\n",
       "      <td id=\"T_ccee0_row22_col1\" class=\"data row22 col1\" >36072</td>\n",
       "      <td id=\"T_ccee0_row22_col2\" class=\"data row22 col2\" >87770</td>\n",
       "      <td id=\"T_ccee0_row22_col3\" class=\"data row22 col3\" >70.87%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccee0_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_ccee0_row23_col0\" class=\"data row23 col0\" >currency</td>\n",
       "      <td id=\"T_ccee0_row23_col1\" class=\"data row23 col1\" >36072</td>\n",
       "      <td id=\"T_ccee0_row23_col2\" class=\"data row23 col2\" >87770</td>\n",
       "      <td id=\"T_ccee0_row23_col3\" class=\"data row23 col3\" >70.87%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccee0_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_ccee0_row24_col0\" class=\"data row24 col0\" >min_salary</td>\n",
       "      <td id=\"T_ccee0_row24_col1\" class=\"data row24 col1\" >29792</td>\n",
       "      <td id=\"T_ccee0_row24_col2\" class=\"data row24 col2\" >94050</td>\n",
       "      <td id=\"T_ccee0_row24_col3\" class=\"data row24 col3\" >75.94%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccee0_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_ccee0_row25_col0\" class=\"data row25 col0\" >max_salary</td>\n",
       "      <td id=\"T_ccee0_row25_col1\" class=\"data row25 col1\" >29792</td>\n",
       "      <td id=\"T_ccee0_row25_col2\" class=\"data row25 col2\" >94050</td>\n",
       "      <td id=\"T_ccee0_row25_col3\" class=\"data row25 col3\" >75.94%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccee0_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_ccee0_row26_col0\" class=\"data row26 col0\" >applies</td>\n",
       "      <td id=\"T_ccee0_row26_col1\" class=\"data row26 col1\" >23318</td>\n",
       "      <td id=\"T_ccee0_row26_col2\" class=\"data row26 col2\" >100524</td>\n",
       "      <td id=\"T_ccee0_row26_col3\" class=\"data row26 col3\" >81.17%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccee0_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_ccee0_row27_col0\" class=\"data row27 col0\" >remote_allowed</td>\n",
       "      <td id=\"T_ccee0_row27_col1\" class=\"data row27 col1\" >15243</td>\n",
       "      <td id=\"T_ccee0_row27_col2\" class=\"data row27 col2\" >108599</td>\n",
       "      <td id=\"T_ccee0_row27_col3\" class=\"data row27 col3\" >87.69%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccee0_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_ccee0_row28_col0\" class=\"data row28 col0\" >med_salary</td>\n",
       "      <td id=\"T_ccee0_row28_col1\" class=\"data row28 col1\" >6280</td>\n",
       "      <td id=\"T_ccee0_row28_col2\" class=\"data row28 col2\" >117562</td>\n",
       "      <td id=\"T_ccee0_row28_col3\" class=\"data row28 col3\" >94.93%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccee0_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_ccee0_row29_col0\" class=\"data row29 col0\" >skills_desc</td>\n",
       "      <td id=\"T_ccee0_row29_col1\" class=\"data row29 col1\" >2439</td>\n",
       "      <td id=\"T_ccee0_row29_col2\" class=\"data row29 col2\" >121403</td>\n",
       "      <td id=\"T_ccee0_row29_col3\" class=\"data row29 col3\" >98.03%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccee0_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "      <td id=\"T_ccee0_row30_col0\" class=\"data row30 col0\" >closed_time</td>\n",
       "      <td id=\"T_ccee0_row30_col1\" class=\"data row30 col1\" >1071</td>\n",
       "      <td id=\"T_ccee0_row30_col2\" class=\"data row30 col2\" >122771</td>\n",
       "      <td id=\"T_ccee0_row30_col3\" class=\"data row30 col3\" >99.14%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x32a8de3c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ‚úÖ Calculate missing values, available count, and percentage\n",
    "missing_values = data.isnull().sum().to_frame(name='missing_count')\n",
    "missing_values['available_count'] = len(data) - missing_values['missing_count']\n",
    "missing_values['missing_percentage'] = (missing_values['missing_count'] / len(data)) * 100  # Keep as float\n",
    "\n",
    "# ‚úÖ Reorder columns for better readability (available_count first)\n",
    "missing_values = missing_values[['available_count', 'missing_count', 'missing_percentage']]\n",
    "\n",
    "# ‚úÖ Sort by missing percentage (ascending for better features on top)\n",
    "missing_values = missing_values.sort_values(by='missing_percentage', ascending=True)\n",
    "\n",
    "# ‚úÖ Reset index and rename it to \"column_name\"\n",
    "missing_values = missing_values.reset_index().rename(columns={'index': 'column_name'})\n",
    "\n",
    "# ‚úÖ Apply clear and meaningful color formatting\n",
    "styled_missing_values = (\n",
    "    missing_values.style\n",
    "    .background_gradient(subset=['available_count'], cmap='Greens')  # More available ‚Üí Green (good)\n",
    "    .background_gradient(subset=['missing_count'], cmap='Oranges_r')  # More missing ‚Üí Darker Orange (bad)\n",
    "    .background_gradient(subset=['missing_percentage'], cmap='Reds_r')  # Higher missing % ‚Üí Darker Red (bad)\n",
    "    .format({'missing_percentage': \"{:.2f}%\"})  # Format as percentage AFTER styling\n",
    ")\n",
    "\n",
    "# ‚úÖ Display dataset size\n",
    "print(f\"The dataset size: {data.shape[0]} rows\")\n",
    "\n",
    "# ‚úÖ Display missing values table with improved color usage\n",
    "display(styled_missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab73790",
   "metadata": {},
   "source": [
    "As we can see, there's a significant amount of missing data, however we will drop columns for every usecase we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded84325",
   "metadata": {},
   "source": [
    "preprocessing to perform:\n",
    "1. lowercasing\n",
    "2. noise removal -> removing punctuations, emoticon, hashtags, accent marks or diacritics, extra white spaces, special characters, digits (could be useful for sentiment analysis though!!!!)\n",
    "3. stop word removal -> removing stop words, sparse terms, and particular words. You can use already existing stop words lists or you can create a custom one for your use case.\n",
    "4. tokenization -> breaking it down into smaller, minimal, meaningful units to work with. It enables to analyze each element in context of the other elements\n",
    "5. lemmatization/stemming -> reduce the words to their root forms, reducing the bias introduced by the inflection, Lemmatization transforms words to the actual root. You have to know the POS of the word to get the correct lemma. The root form, in the stemming case, is a truncated one: stemming is a process that chops off the ends of words.\n",
    "6. token enrichment -> POS tagging -> gives a mark to words based on the part-of speech they are, such as nouns, verbs and adjectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb2019b",
   "metadata": {},
   "source": [
    "## Skill Extraction and Clustering\n",
    "\n",
    "### Objective: Extract required skills from job descriptions and cluster them to identify common skill sets across industries.\n",
    "\n",
    "NLP Techniques: Named Entity Recognition (NER), Topic Modeling, or Clustering algorithms.\n",
    "\n",
    "Research Questions:\n",
    "‚óã What are the most in-demand skills across different sectors?\n",
    "‚óã How do skill requirements differ by salary range or job title?\n",
    "‚óã What are the salary ranges in different sectors and job positions?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8515b6af",
   "metadata": {},
   "source": [
    "## Preprocessing the dataset for skill extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9bf1e95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-trf==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_trf-3.8.0/en_core_web_trf-3.8.0-py3-none-any.whl (457.4 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m457.4/457.4 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m  \u001b[33m0:00:31\u001b[0m:00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy-curated-transformers<1.0.0,>=0.2.2 in ./.venv/lib/python3.13/site-packages (from en-core-web-trf==3.8.0) (0.3.1)\n",
      "Requirement already satisfied: curated-transformers<0.2.0,>=0.1.0 in ./.venv/lib/python3.13/site-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (0.1.1)\n",
      "Requirement already satisfied: curated-tokenizers<0.1.0,>=0.0.9 in ./.venv/lib/python3.13/site-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (0.0.9)\n",
      "Requirement already satisfied: torch>=1.12.0 in ./.venv/lib/python3.13/site-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2.8.0)\n",
      "Requirement already satisfied: regex>=2022 in ./.venv/lib/python3.13/site-packages (from curated-tokenizers<0.1.0,>=0.0.9->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2025.9.18)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.13/site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.13/site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.13/site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.13/site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2025.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.0.2)\n",
      "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_trf')\n"
     ]
    }
   ],
   "source": [
    "# en_core_sm was not performing well so we will try the 'trf' version\n",
    "!python -m spacy download en_core_web_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8a190cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in ./.venv/lib/python3.13/site-packages (3.8.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./.venv/lib/python3.13/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./.venv/lib/python3.13/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./.venv/lib/python3.13/site-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./.venv/lib/python3.13/site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./.venv/lib/python3.13/site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in ./.venv/lib/python3.13/site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./.venv/lib/python3.13/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./.venv/lib/python3.13/site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./.venv/lib/python3.13/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in ./.venv/lib/python3.13/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in ./.venv/lib/python3.13/site-packages (from spacy) (0.19.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./.venv/lib/python3.13/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./.venv/lib/python3.13/site-packages (from spacy) (2.3.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./.venv/lib/python3.13/site-packages (from spacy) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./.venv/lib/python3.13/site-packages (from spacy) (2.11.9)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from spacy) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./.venv/lib/python3.13/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in ./.venv/lib/python3.13/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in ./.venv/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.8.3)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in ./.venv/lib/python3.13/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./.venv/lib/python3.13/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.13/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.3.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./.venv/lib/python3.13/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./.venv/lib/python3.13/site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.1.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in ./.venv/lib/python3.13/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.22.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in ./.venv/lib/python3.13/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.1)\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.13/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.3)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in ./.venv/lib/python3.13/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.13/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.13/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->spacy) (3.0.3)\n",
      "Requirement already satisfied: spacy-transformers in ./.venv/lib/python3.13/site-packages (1.3.9)\n",
      "Requirement already satisfied: spacy<4.1.0,>=3.5.0 in ./.venv/lib/python3.13/site-packages (from spacy-transformers) (3.8.7)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./.venv/lib/python3.13/site-packages (from spacy-transformers) (2.3.3)\n",
      "Requirement already satisfied: transformers<4.50.0,>=3.4.0 in ./.venv/lib/python3.13/site-packages (from spacy-transformers) (4.49.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in ./.venv/lib/python3.13/site-packages (from spacy-transformers) (2.8.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in ./.venv/lib/python3.13/site-packages (from spacy-transformers) (2.5.1)\n",
      "Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in ./.venv/lib/python3.13/site-packages (from spacy-transformers) (0.9.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./.venv/lib/python3.13/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./.venv/lib/python3.13/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./.venv/lib/python3.13/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./.venv/lib/python3.13/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./.venv/lib/python3.13/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in ./.venv/lib/python3.13/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./.venv/lib/python3.13/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (1.1.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./.venv/lib/python3.13/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in ./.venv/lib/python3.13/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in ./.venv/lib/python3.13/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (0.19.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./.venv/lib/python3.13/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./.venv/lib/python3.13/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./.venv/lib/python3.13/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (2.11.9)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (25.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./.venv/lib/python3.13/site-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in ./.venv/lib/python3.13/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.1.0,>=3.5.0->spacy-transformers) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.1.0,>=3.5.0->spacy-transformers) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in ./.venv/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.1.0,>=3.5.0->spacy-transformers) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.1.0,>=3.5.0->spacy-transformers) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (2025.8.3)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in ./.venv/lib/python3.13/site-packages (from thinc<8.4.0,>=8.3.4->spacy<4.1.0,>=3.5.0->spacy-transformers) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./.venv/lib/python3.13/site-packages (from thinc<8.4.0,>=8.3.4->spacy<4.1.0,>=3.5.0->spacy-transformers) (0.1.5)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from transformers<4.50.0,>=3.4.0->spacy-transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in ./.venv/lib/python3.13/site-packages (from transformers<4.50.0,>=3.4.0->spacy-transformers) (0.35.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.13/site-packages (from transformers<4.50.0,>=3.4.0->spacy-transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.13/site-packages (from transformers<4.50.0,>=3.4.0->spacy-transformers) (2025.9.18)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.13/site-packages (from transformers<4.50.0,>=3.4.0->spacy-transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.venv/lib/python3.13/site-packages (from transformers<4.50.0,>=3.4.0->spacy-transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers<4.50.0,>=3.4.0->spacy-transformers) (2025.9.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers<4.50.0,>=3.4.0->spacy-transformers) (1.1.10)\n",
      "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.13/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (8.3.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./.venv/lib/python3.13/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./.venv/lib/python3.13/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (14.1.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in ./.venv/lib/python3.13/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (0.22.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in ./.venv/lib/python3.13/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (7.3.1)\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.13/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (1.17.3)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in ./.venv/lib/python3.13/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (1.3.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.13/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.13/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (0.1.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.13/site-packages (from torch>=1.8.0->spacy-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.13/site-packages (from torch>=1.8.0->spacy-transformers) (3.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.8.0->spacy-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->spacy<4.1.0,>=3.5.0->spacy-transformers) (3.0.3)\n",
      "Collecting en-core-web-trf==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_trf-3.8.0/en_core_web_trf-3.8.0-py3-none-any.whl (457.4 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m457.4/457.4 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m  \u001b[33m0:00:16\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy-curated-transformers<1.0.0,>=0.2.2 in ./.venv/lib/python3.13/site-packages (from en-core-web-trf==3.8.0) (0.3.1)\n",
      "Requirement already satisfied: curated-transformers<0.2.0,>=0.1.0 in ./.venv/lib/python3.13/site-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (0.1.1)\n",
      "Requirement already satisfied: curated-tokenizers<0.1.0,>=0.0.9 in ./.venv/lib/python3.13/site-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (0.0.9)\n",
      "Requirement already satisfied: torch>=1.12.0 in ./.venv/lib/python3.13/site-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2.8.0)\n",
      "Requirement already satisfied: regex>=2022 in ./.venv/lib/python3.13/site-packages (from curated-tokenizers<0.1.0,>=0.0.9->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2025.9.18)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.13/site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.13/site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.13/site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.13/site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2025.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.0.3)\n",
      "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_trf')\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!pip install spacy-transformers\n",
    "!python3 -m spacy download en_core_web_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22e3ec6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E002] Can't find factory for 'curated_transformer' for language English (en). This usually happens when spaCy calls `nlp.create_pipe` with a custom component name that's not registered on the current language class. If you're using a custom component, make sure you've added the decorator `@Language.component` (for function components) or `@Language.factory` (for class components).\n\nAvailable factories: merge_noun_chunks, merge_entities, merge_subtokens, en.lemmatizer",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[73]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load the small English spaCy model.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# This model includes lemmatization, stop words, and tokenization capabilities.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     nlp = \u001b[43mspacy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43men_core_web_trf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDownloading \u001b[39m\u001b[33m'\u001b[39m\u001b[33men_core_web_trf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m model...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/spacy/__init__.py:52\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(name, vocab, disable, enable, exclude, config)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\n\u001b[32m     29\u001b[39m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[32m     30\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m     35\u001b[39m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] = util.SimpleFrozenDict(),\n\u001b[32m     36\u001b[39m ) -> Language:\n\u001b[32m     37\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[32m     38\u001b[39m \n\u001b[32m     39\u001b[39m \u001b[33;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     50\u001b[39m \u001b[33;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/spacy/util.py:477\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(name, vocab, disable, enable, exclude, config)\u001b[39m\n\u001b[32m    475\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m get_lang_class(name.replace(\u001b[33m\"\u001b[39m\u001b[33mblank:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m))()\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_package(name):  \u001b[38;5;66;03m# installed as package\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model_from_package\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m Path(name).exists():  \u001b[38;5;66;03m# path to model data directory\u001b[39;00m\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m load_model_from_path(Path(name), **kwargs)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/spacy/util.py:513\u001b[39m, in \u001b[36mload_model_from_package\u001b[39m\u001b[34m(name, vocab, disable, enable, exclude, config)\u001b[39m\n\u001b[32m    496\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load a model from an installed package.\u001b[39;00m\n\u001b[32m    497\u001b[39m \n\u001b[32m    498\u001b[39m \u001b[33;03mname (str): The package name.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    510\u001b[39m \u001b[33;03mRETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[32m    511\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    512\u001b[39m \u001b[38;5;28mcls\u001b[39m = importlib.import_module(name)\n\u001b[32m--> \u001b[39m\u001b[32m513\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/en_core_web_trf/__init__.py:10\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(**overrides)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(**overrides):\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model_from_init_py\u001b[49m\u001b[43m(\u001b[49m\u001b[34;43m__file__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/spacy/util.py:694\u001b[39m, in \u001b[36mload_model_from_init_py\u001b[39m\u001b[34m(init_file, vocab, disable, enable, exclude, config)\u001b[39m\n\u001b[32m    692\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_path.exists():\n\u001b[32m    693\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors.E052.format(path=data_path))\n\u001b[32m--> \u001b[39m\u001b[32m694\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model_from_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m    \u001b[49m\u001b[43menable\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/spacy/util.py:551\u001b[39m, in \u001b[36mload_model_from_path\u001b[39m\u001b[34m(model_path, meta, vocab, disable, enable, exclude, config)\u001b[39m\n\u001b[32m    549\u001b[39m overrides = dict_to_dot(config, for_overrides=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    550\u001b[39m config = load_config(config_path, overrides=overrides)\n\u001b[32m--> \u001b[39m\u001b[32m551\u001b[39m nlp = \u001b[43mload_model_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m    \u001b[49m\u001b[43menable\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m nlp.from_disk(model_path, exclude=exclude, overrides=overrides)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/spacy/util.py:599\u001b[39m, in \u001b[36mload_model_from_config\u001b[39m\u001b[34m(config, meta, vocab, disable, enable, exclude, auto_fill, validate)\u001b[39m\n\u001b[32m    596\u001b[39m \u001b[38;5;66;03m# This will automatically handle all codes registered via the languages\u001b[39;00m\n\u001b[32m    597\u001b[39m \u001b[38;5;66;03m# registry, including custom subclasses provided via entry points\u001b[39;00m\n\u001b[32m    598\u001b[39m lang_cls = get_lang_class(nlp_config[\u001b[33m\"\u001b[39m\u001b[33mlang\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m nlp = \u001b[43mlang_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    602\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[43m    \u001b[49m\u001b[43menable\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    604\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauto_fill\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauto_fill\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    608\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    609\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m nlp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/spacy/language.py:1893\u001b[39m, in \u001b[36mLanguage.from_config\u001b[39m\u001b[34m(cls, config, vocab, disable, enable, exclude, meta, auto_fill, validate)\u001b[39m\n\u001b[32m   1890\u001b[39m     factory = pipe_cfg.pop(\u001b[33m\"\u001b[39m\u001b[33mfactory\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1891\u001b[39m     \u001b[38;5;66;03m# The pipe name (key in the config) here is the unique name\u001b[39;00m\n\u001b[32m   1892\u001b[39m     \u001b[38;5;66;03m# of the component, not necessarily the factory\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1893\u001b[39m     \u001b[43mnlp\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_pipe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1894\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfactory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1895\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpipe_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1896\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpipe_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1897\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1898\u001b[39m \u001b[43m        \u001b[49m\u001b[43mraw_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraw_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1899\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1900\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1901\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m pipe_cfg\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/spacy/language.py:825\u001b[39m, in \u001b[36mLanguage.add_pipe\u001b[39m\u001b[34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[39m\n\u001b[32m    821\u001b[39m     pipe_component, factory_name = \u001b[38;5;28mself\u001b[39m.create_pipe_from_source(\n\u001b[32m    822\u001b[39m         factory_name, source, name=name\n\u001b[32m    823\u001b[39m     )\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m     pipe_component = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_pipe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfactory_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    828\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    829\u001b[39m \u001b[43m        \u001b[49m\u001b[43mraw_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraw_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    832\u001b[39m pipe_index = \u001b[38;5;28mself\u001b[39m._get_pipe_index(before, after, first, last)\n\u001b[32m    833\u001b[39m \u001b[38;5;28mself\u001b[39m._pipe_meta[name] = \u001b[38;5;28mself\u001b[39m.get_factory_meta(factory_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/spacy/language.py:694\u001b[39m, in \u001b[36mLanguage.create_pipe\u001b[39m\u001b[34m(self, factory_name, name, config, raw_config, validate)\u001b[39m\n\u001b[32m    686\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.has_factory(factory_name):\n\u001b[32m    687\u001b[39m     err = Errors.E002.format(\n\u001b[32m    688\u001b[39m         name=factory_name,\n\u001b[32m    689\u001b[39m         opts=\u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mself\u001b[39m.factory_names),\n\u001b[32m   (...)\u001b[39m\u001b[32m    692\u001b[39m         lang_code=\u001b[38;5;28mself\u001b[39m.lang,\n\u001b[32m    693\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m694\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err)\n\u001b[32m    695\u001b[39m pipe_meta = \u001b[38;5;28mself\u001b[39m.get_factory_meta(factory_name)\n\u001b[32m    696\u001b[39m \u001b[38;5;66;03m# This is unideal, but the alternative would mean you always need to\u001b[39;00m\n\u001b[32m    697\u001b[39m \u001b[38;5;66;03m# specify the full config settings, which is not really viable.\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: [E002] Can't find factory for 'curated_transformer' for language English (en). This usually happens when spaCy calls `nlp.create_pipe` with a custom component name that's not registered on the current language class. If you're using a custom component, make sure you've added the decorator `@Language.component` (for function components) or `@Language.factory` (for class components).\n\nAvailable factories: merge_noun_chunks, merge_entities, merge_subtokens, en.lemmatizer"
     ]
    }
   ],
   "source": [
    "# Load the small English spaCy model.\n",
    "# This model includes lemmatization, stop words, and tokenization capabilities.\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    print(\"Downloading 'en_core_web_sm' model...\")\n",
    "    from spacy.cli import download\n",
    "    download(\"en_core_web_sm\")\n",
    "    nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eb1e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Performs a series of text preprocessing steps:\n",
    "    1. Removes special characters and numbers.\n",
    "    2. Converts text to lowercase.\n",
    "    3. Tokenizes the text.\n",
    "    4. Removes stop words.\n",
    "    5. Lemmatizes the tokens.\n",
    "\n",
    "    Args:\n",
    "        text: The raw text string to be preprocessed.\n",
    "\n",
    "    Returns:\n",
    "        The preprocessed and cleaned text string.\n",
    "    \"\"\"\n",
    "    # Check if the input is a valid string. If not, return an empty string.\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # 1. Remove special characters, punctuation, and numbers.\n",
    "    # We'll keep spaces and letters.\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text, re.I|re.A)\n",
    "\n",
    "    # Convert to a spaCy Doc object for efficient processing.\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # 2. Convert to lowercase, remove leading/trailing whitespace, and perform. Note - conversion to lowercase is handled implicitly by spaCy during lemmatization\n",
    "    #    stop word removal and lemmatization.\n",
    "    # A list comprehension is used for efficiency.\n",
    "    tokens = [\n",
    "        token.lemma_ for token in doc\n",
    "        if not token.is_stop and not token.is_punct and token.is_alpha\n",
    "    ]\n",
    "\n",
    "    # Join the processed tokens back into a single string.\n",
    "    return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a94a0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_job_descriptions(df: pd.DataFrame, column_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Applies the text preprocessing function to a specified column in a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df: The pandas DataFrame containing the raw data.\n",
    "        column_name: The name of the column with the job description text.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame with a 'preprocessed_text' column.\n",
    "    \"\"\"\n",
    "    # Ensure the specified column exists in the DataFrame.\n",
    "    if column_name not in df.columns:\n",
    "        print(f\"Error: Column '{column_name}' not found in DataFrame.\")\n",
    "        return df\n",
    "\n",
    "    # Apply the preprocess_text function to each entry in the column.\n",
    "    print(\"Preprocessing job descriptions...\")\n",
    "    data = df.copy()\n",
    "    data['preprocessed_text'] = data[column_name].apply(preprocess_text)\n",
    "    print(\"Preprocessing complete!\")\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "389e9421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "            job_id                                        description\n",
      "73457   3902931205  Warehouse Associate\\n\\nSince 2022, Associated ...\n",
      "31563   3894855473  Interested in joining our influencer talent ma...\n",
      "41620   3899525675  Talent Specialist - Hybrid Role Must be locate...\n",
      "10762   3887106339  The ideal Salesperson is passionate about fash...\n",
      "30334   3894555810  1126363_RR00090444 Job ID: 1126363_RR00090444\\...\n",
      "...            ...                                                ...\n",
      "106731  3905328899  Job Description\\n\\n INTEGRIS Health Baptist Me...\n",
      "29871   3894540767  About Raise Commercial Real Estate\\n\\nRaise is...\n",
      "50360   3901372681  Job SummaryThe Paid Ads Manager will play an i...\n",
      "84824   3904362789  Mechanical Engineer ‚Äì Design Support (National...\n",
      "51656   3901391118  Do you want to work for the global leader in t...\n",
      "\n",
      "[10000 rows x 2 columns]\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Preprocessing job descriptions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kh/wsd4_v7x1vsbp92ff9vfj0q80000gn/T/ipykernel_27817/2386819784.py:22: DeprecationWarning: 'count' is passed as positional argument\n",
      "  text = re.sub(r'[^a-zA-Z\\s]', '', text, re.I|re.A)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m30\u001b[39m + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Preprocess the 'description' column.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m preprocessed_df = \u001b[43mpreprocess_job_descriptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdescription\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Print the resulting DataFrame to see the preprocessed text.\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPreprocessed DataFrame:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mpreprocess_job_descriptions\u001b[39m\u001b[34m(df, column_name)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Apply the preprocess_text function to each entry in the column.\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPreprocessing job descriptions...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mpreprocessed_text\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPreprocessing complete!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/pandas/core/series.py:4935\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4800\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4801\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4802\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4807\u001b[39m     **kwargs,\n\u001b[32m   4808\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4809\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4810\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4811\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4926\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4927\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4928\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4929\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4930\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4931\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4932\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4933\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4934\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4935\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/pandas/core/apply.py:1422\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1421\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1422\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/pandas/core/apply.py:1502\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1496\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1498\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1499\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1500\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1501\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1502\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1507\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1508\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/pandas/core/base.py:925\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    923\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/pandas/core/algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:2999\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mpreprocess_text\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m     22\u001b[39m text = re.sub(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m[^a-zA-Z\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms]\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, text, re.I|re.A)\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Convert to a spaCy Doc object for efficient processing.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m doc = \u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# 2. Convert to lowercase, remove leading/trailing whitespace, and perform\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m#    stop word removal and lemmatization.\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# A list comprehension is used for efficiency.\u001b[39;00m\n\u001b[32m     30\u001b[39m tokens = [\n\u001b[32m     31\u001b[39m     token.lemma_ \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m doc\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m token.is_stop \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m token.is_punct \u001b[38;5;129;01mand\u001b[39;00m token.is_alpha\n\u001b[32m     33\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/spacy/language.py:1053\u001b[39m, in \u001b[36mLanguage.__call__\u001b[39m\u001b[34m(self, text, disable, component_cfg)\u001b[39m\n\u001b[32m   1051\u001b[39m     error_handler = proc.get_error_handler()\n\u001b[32m   1052\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1053\u001b[39m     doc = \u001b[43mproc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcomponent_cfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1055\u001b[39m     \u001b[38;5;66;03m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[32m   1056\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors.E109.format(name=name)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/spacy/pipeline/trainable_pipe.pyx:52\u001b[39m, in \u001b[36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/spacy/pipeline/tok2vec.py:121\u001b[39m, in \u001b[36mTok2Vec.predict\u001b[39m\u001b[34m(self, docs)\u001b[39m\n\u001b[32m    119\u001b[39m     width = \u001b[38;5;28mself\u001b[39m.model.get_dim(\u001b[33m\"\u001b[39m\u001b[33mnO\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m.model.ops.alloc((\u001b[32m0\u001b[39m, width)) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs]\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m tokvecs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tokvecs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/thinc/model.py:334\u001b[39m, in \u001b[36mModel.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT) -> OutT:\n\u001b[32m    331\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[32m    332\u001b[39m \u001b[33;03m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[32m    333\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/thinc/layers/chain.py:54\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, X, is_train)\u001b[39m\n\u001b[32m     52\u001b[39m callbacks = []\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model.layers:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     Y, inc_layer_grad = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     callbacks.append(inc_layer_grad)\n\u001b[32m     56\u001b[39m     X = Y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/thinc/model.py:310\u001b[39m, in \u001b[36mModel.__call__\u001b[39m\u001b[34m(self, X, is_train)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) -> Tuple[OutT, Callable]:\n\u001b[32m    308\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[33;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/thinc/layers/with_array.py:42\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, Xseq, is_train)\u001b[39m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model.layers[\u001b[32m0\u001b[39m](Xseq, is_train)\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], \u001b[43m_list_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/thinc/layers/with_array.py:77\u001b[39m, in \u001b[36m_list_forward\u001b[39m\u001b[34m(model, Xs, is_train)\u001b[39m\n\u001b[32m     75\u001b[39m lengths = NUMPY_OPS.asarray1i([\u001b[38;5;28mlen\u001b[39m(seq) \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m Xs])\n\u001b[32m     76\u001b[39m Xf = layer.ops.flatten(Xs, pad=pad)\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m Yf, get_dXf = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbackprop\u001b[39m(dYs: ListXd) -> ListXd:\n\u001b[32m     80\u001b[39m     dYf = layer.ops.flatten(dYs, pad=pad)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/thinc/model.py:310\u001b[39m, in \u001b[36mModel.__call__\u001b[39m\u001b[34m(self, X, is_train)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) -> Tuple[OutT, Callable]:\n\u001b[32m    308\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[33;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/thinc/layers/chain.py:54\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, X, is_train)\u001b[39m\n\u001b[32m     52\u001b[39m callbacks = []\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model.layers:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     Y, inc_layer_grad = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     callbacks.append(inc_layer_grad)\n\u001b[32m     56\u001b[39m     X = Y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/thinc/model.py:310\u001b[39m, in \u001b[36mModel.__call__\u001b[39m\u001b[34m(self, X, is_train)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) -> Tuple[OutT, Callable]:\n\u001b[32m    308\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[33;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/thinc/layers/residual.py:41\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, X, is_train)\u001b[39m\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     39\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m d_output + dX\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m Y, backprop_layer = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [X[i] + Y[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X))], backprop\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/thinc/model.py:310\u001b[39m, in \u001b[36mModel.__call__\u001b[39m\u001b[34m(self, X, is_train)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) -> Tuple[OutT, Callable]:\n\u001b[32m    308\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[33;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/thinc/layers/chain.py:54\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, X, is_train)\u001b[39m\n\u001b[32m     52\u001b[39m callbacks = []\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model.layers:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     Y, inc_layer_grad = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     callbacks.append(inc_layer_grad)\n\u001b[32m     56\u001b[39m     X = Y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/thinc/model.py:310\u001b[39m, in \u001b[36mModel.__call__\u001b[39m\u001b[34m(self, X, is_train)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) -> Tuple[OutT, Callable]:\n\u001b[32m    308\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[33;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/thinc/layers/chain.py:54\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, X, is_train)\u001b[39m\n\u001b[32m     52\u001b[39m callbacks = []\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model.layers:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     Y, inc_layer_grad = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     callbacks.append(inc_layer_grad)\n\u001b[32m     56\u001b[39m     X = Y\n",
      "    \u001b[31m[... skipping similar frames: Model.__call__ at line 310 (1 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/thinc/layers/chain.py:54\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, X, is_train)\u001b[39m\n\u001b[32m     52\u001b[39m callbacks = []\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model.layers:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     Y, inc_layer_grad = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     callbacks.append(inc_layer_grad)\n\u001b[32m     56\u001b[39m     X = Y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/thinc/model.py:310\u001b[39m, in \u001b[36mModel.__call__\u001b[39m\u001b[34m(self, X, is_train)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) -> Tuple[OutT, Callable]:\n\u001b[32m    308\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[33;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/thinc/layers/maxout.py:52\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, X, is_train)\u001b[39m\n\u001b[32m     50\u001b[39m W = model.get_param(\u001b[33m\"\u001b[39m\u001b[33mW\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     51\u001b[39m W = model.ops.reshape2f(W, nO * nP, nI)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m Y = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgemm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans2\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m Y += model.ops.reshape1f(b, nO * nP)\n\u001b[32m     54\u001b[39m Z = model.ops.reshape3f(Y, Y.shape[\u001b[32m0\u001b[39m], nO, nP)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# making a copy of the dataset for further processing\n",
    "# Random Sampling\n",
    "# The dataframe contains 123,849 rows, embedding all rows will lead to excessive computational cost for this demo. We will select 10000 rows for job postings.\n",
    "df = data.sample(10000, random_state=42).copy()\n",
    "# keeping only the relevant columns for skill extraction\n",
    "df = df[['job_id', 'description']]\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")\n",
    "\n",
    "# Preprocess the 'description' column.\n",
    "preprocessed_df = preprocess_job_descriptions(df, 'description')\n",
    "\n",
    "# Print the resulting DataFrame to see the preprocessed text.\n",
    "print(\"Preprocessed DataFrame:\")\n",
    "print(preprocessed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59609345",
   "metadata": {},
   "source": [
    "## Skill extraction\n",
    "We perform skill extraction using a pre-trained SpaCy model and we will later finetune it on our own curated labeled data to enhance accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "698b8f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_skills(text: str) -> list:\n",
    "    \"\"\"\n",
    "    Extracts entities from text using a pre-trained spaCy NER model.\n",
    "\n",
    "    Args:\n",
    "        text: The raw or preprocessed job description text.\n",
    "\n",
    "    Returns:\n",
    "        A list of extracted strings that are identified as potential skills.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "\n",
    "    # Process the text with the spaCy NLP pipeline\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Simple filtering for potential skills.\n",
    "    # This is a heuristic approach, as 'en_core_web_sm' doesn't have a 'SKILL' label.\n",
    "    # We will primarily look for common nouns or noun phrases that might represent skills.\n",
    "    \n",
    "    # You can also iterate through `doc.ents` for a more explicit list of entities\n",
    "    # recognized by the default model (e.g., ORG, GPE, DATE).\n",
    "    \n",
    "    # For a more robust approach, you'll need to create a list of skills to match\n",
    "    # or fine-tune a model as discussed previously.\n",
    "    \n",
    "    # A simple example: extracting proper nouns and compound nouns\n",
    "    skills = []\n",
    "    for chunk in doc.noun_chunks:\n",
    "        # Filter for phrases that are likely to be skills\n",
    "        # This is a very basic filter; it will need to be refined.\n",
    "        if \"data\" in chunk.text.lower() or \"learning\" in chunk.text.lower(): # TODO: Expand this list - make filter more comprehensive\n",
    "            skills.append(chunk.text.strip())\n",
    "\n",
    "    return list(set(skills)) # Return unique skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceb2601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe_for_skills(df: pd.DataFrame, text_column: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Applies skill extraction to a DataFrame column.\n",
    "\n",
    "    Args:\n",
    "        df: The pandas DataFrame.\n",
    "        text_column: The name of the column containing the job description text.\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame with a new column 'extracted_skills'.\n",
    "    \"\"\"\n",
    "    print(\"Starting skill extraction...\")\n",
    "    data = df.copy()\n",
    "    data['extracted_skills'] = data[text_column].apply(extract_skills)\n",
    "    print(\"Skill extraction complete!\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b58c30cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting skill extraction...\n",
      "Skill extraction complete!\n",
      "DataFrame with Extracted Skills:\n",
      "            job_id                                        description  \\\n",
      "73457   3902931205  Warehouse Associate\\n\\nSince 2022, Associated ...   \n",
      "31563   3894855473  Interested in joining our influencer talent ma...   \n",
      "41620   3899525675  Talent Specialist - Hybrid Role Must be locate...   \n",
      "10762   3887106339  The ideal Salesperson is passionate about fash...   \n",
      "30334   3894555810  1126363_RR00090444 Job ID: 1126363_RR00090444\\...   \n",
      "...            ...                                                ...   \n",
      "106731  3905328899  Job Description\\n\\n INTEGRIS Health Baptist Me...   \n",
      "29871   3894540767  About Raise Commercial Real Estate\\n\\nRaise is...   \n",
      "50360   3901372681  Job SummaryThe Paid Ads Manager will play an i...   \n",
      "84824   3904362789  Mechanical Engineer ‚Äì Design Support (National...   \n",
      "51656   3901391118  Do you want to work for the global leader in t...   \n",
      "\n",
      "                                        preprocessed_text  \\\n",
      "73457   Warehouse Associate Associated Materials Alsid...   \n",
      "31563   interested join influencer talent management t...   \n",
      "41620   Talent Specialist Hybrid Role locate Greenvill...   \n",
      "10762   ideal Salesperson passionate fashion styling a...   \n",
      "30334   RR Job ID RR NYU Langone HospitalLong Island b...   \n",
      "...                                                   ...   \n",
      "106731  Job Description INTEGRIS Health Baptist Medica...   \n",
      "29871   raise commercial Real Estate Raise modern real...   \n",
      "50360   Job SummaryThe Paid Ads Manager play instrumen...   \n",
      "84824   Mechanical Engineer Design Support National Ca...   \n",
      "51656   want work global leader language service techn...   \n",
      "\n",
      "                                         extracted_skills  \n",
      "73457                                                  []  \n",
      "31563                                                  []  \n",
      "41620                                                  []  \n",
      "10762                                                  []  \n",
      "30334                                   [data collection]  \n",
      "...                                                   ...  \n",
      "106731  [lifelong learning, all initial and annual req...  \n",
      "29871                                                  []  \n",
      "50360           [learnings, in-depth data analysis, data]  \n",
      "84824                                                  []  \n",
      "51656                                          [learning]  \n",
      "\n",
      "[10000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Apply the skill extraction function.\n",
    "extracted_skills_df = process_dataframe_for_skills(preprocessed_df, 'description')\n",
    "\n",
    "print(\"DataFrame with Extracted Skills:\")\n",
    "print(extracted_skills_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5a1532",
   "metadata": {},
   "source": [
    "### As we can see the model without any finetuning is not extracting skills well. We will begin the finetuning process by preparing a custom training dataset with the labels we want to define."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c0b238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessed_df.to_csv('preprocessed_job_postings.csv', index=False)\n",
    "preprocessed_df[['job_id', 'preprocessed_text']].to_csv('preprocessed_job_postings_transformer.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f4b6f272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['job_id', 'description', 'preprocessed_text', 'extracted_skills'], dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "13c53894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['job_id', 'description', 'preprocessed_text', 'extracted_skills'], dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_skills_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100a5c5d",
   "metadata": {},
   "source": [
    "## Finetuning the SpaCy NLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3746ac43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating DocBin: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 1365.78it/s]\n",
      "Creating DocBin: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 2885.66it/s]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from tqdm import tqdm\n",
    "# import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Prepare the training data\n",
    "# This is a small sample. For your thesis, you will need a much larger dataset.\n",
    "# The format is a tuple: (text, {\"entities\": [(start_char, end_char, \"LABEL\")]})\n",
    "# \"start_char\" and \"end_char\" are the character indices of the entity in the text.\n",
    "train_data = [\n",
    "    (\"We are looking for a data scientist with expertise in Python.\", {\"entities\": [(47, 53, \"SKILL\")]}),\n",
    "    (\"Experience with cloud computing platforms like Amazon Web Services (AWS) is a plus.\", {\"entities\": [(42, 63, \"SKILL\"), (65, 68, \"SKILL\")]}),\n",
    "    (\"Needs strong project management skills.\", {\"entities\": [(11, 29, \"SKILL\")]}),\n",
    "    (\"Seeking a software engineer with strong programming skills in Java and C++.\", {\"entities\": [(49, 53, \"SKILL\"), (58, 61, \"SKILL\")]}),\n",
    "    (\"Knowledge of Google Cloud is a plus.\", {\"entities\": [(13, 25, \"SKILL\")]}),\n",
    "    (\"Proficiency in JavaScript, HTML, and CSS is required.\", {\"entities\": [(16, 26, \"SKILL\"), (28, 32, \"SKILL\"), (38, 41, \"SKILL\")]}),\n",
    "    (\"Familiarity with React and Angular frameworks is a bonus.\", {\"entities\": [(20, 25, \"SKILL\"), (30, 37, \"SKILL\")]}),\n",
    "]\n",
    "\n",
    "# Split the data into training and development sets\n",
    "train_data, dev_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Convert data to spaCy's format\n",
    "# This is an efficient way to store your data for training.\n",
    "def convert_data_to_docbin(data, output_path):\n",
    "    \"\"\"Converts training data to a spaCy DocBin file.\"\"\"\n",
    "\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    # ^ Creates a blank English NLP pipeline. We don't need a full model \n",
    "    # here (like en_core_web_lg), just the tokenization rules.\n",
    "\n",
    "    db = DocBin()\n",
    "    # ^ Initializes the empty DocBin container where all the converted \n",
    "    # documents will be stored.\n",
    "\n",
    "    for text, annotations in tqdm(data, desc=\"Creating DocBin\"):\n",
    "        # `data` is your list of (text, annotations) tuples.\n",
    "        # `tqdm` just adds a progress bar (the 'Creating DocBin' part)\n",
    "        \n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annotations['entities']:\n",
    "            span = doc.char_span(start, end, label=label)\n",
    "            # ^ CRUCIAL STEP: This creates a Span object for the entity. \n",
    "            # It uses the start/end *character indices* to find the corresponding \n",
    "            # *tokens* in the `doc` and assigns the label (\"SKILL\").\n",
    "\n",
    "            if span is not None:\n",
    "                ents.append(span)\n",
    "                # ^ If spaCy successfully created the span (meaning the indices \n",
    "                # correctly align with token boundaries), add it to the list.\n",
    "\n",
    "        doc.ents = ents\n",
    "        # ^ Assigns the newly created list of entities (`ents`) to the document.\n",
    "\n",
    "        db.add(doc)\n",
    "        # ^ Adds the fully annotated document (`doc`) to the DocBin container (`db`).\n",
    "\n",
    "    db.to_disk(output_path)\n",
    "    # ^ Saves the entire DocBin container to the specified file path (e.g., \"train.spacy\").\n",
    "\n",
    "# Run the function to create your training data file\n",
    "convert_data_to_docbin(train_data, \"train.spacy\")\n",
    "convert_data_to_docbin(dev_data, \"dev.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7ea366",
   "metadata": {},
   "source": [
    "## Step 3: Train the model\n",
    "You will need to run the following command in your terminal to create the config file.\n",
    "spacy init config --lang en --pipeline ner --optimize efficiency config.cfg\n",
    "\n",
    "Then, you can run the training from the command line:\n",
    "spacy train config.cfg --output ./output --paths.train ./train.spacy --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7eda7c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[38;5;1m‚úò The provided output file already exists. To force overwriting the\n",
      "config file, set the --force or -F flag.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Train the model\n",
    "# You will need to run the following command in your terminal to create the config file or run this cell in notebook\n",
    "# spacy init config --lang en --pipeline ner --optimize efficiency config.cfg\n",
    "\n",
    "!python -m spacy init config --lang en --pipeline ner --optimize efficiency config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aa0b0943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-01 13:00:02,329] [DEBUG] Config overrides from CLI: ['paths.train']\n",
      "\u001b[38;5;2m‚úî Created output directory: output\u001b[0m\n",
      "\u001b[38;5;4m‚Ñπ Saving to output directory: output\u001b[0m\n",
      "\u001b[38;5;4m‚Ñπ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2025-10-01 13:00:02,500] [INFO] Set up nlp object from config\n",
      "[2025-10-01 13:00:02,508] [DEBUG] Loading corpus from path: dev.spacy\n",
      "[2025-10-01 13:00:02,508] [DEBUG] Loading corpus from path: train.spacy\n",
      "[2025-10-01 13:00:02,509] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2025-10-01 13:00:02,511] [INFO] Created vocabulary\n",
      "[2025-10-01 13:00:02,511] [INFO] Finished initializing nlp object\n",
      "[2025-10-01 13:00:02,548] [DEBUG] [W033] Training a new parser or NER using a model with no lexeme normalization table. This may degrade the performance of the model to some degree. If this is intentional or the language you're using doesn't have a normalization table, please ignore this warning. If this is surprising, make sure you have the spacy-lookups-data package installed and load the table in your config. The languages with lexeme normalization tables are currently: cs, da, de, el, en, grc, id, lb, mk, pt, ru, sr, ta, th\n",
      "\n",
      "Load the table in your config with:\n",
      "\n",
      "[initialize.lookups]\n",
      "@misc = \"spacy.LookupsDataLoader.v1\"\n",
      "lang = ${nlp.lang}\n",
      "tables = [\"lexeme_norm\"]\n",
      "\n",
      "[2025-10-01 13:00:02,632] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
      "\u001b[38;5;2m‚úî Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[2025-10-01 13:00:02,641] [DEBUG] Loading corpus from path: dev.spacy\n",
      "[2025-10-01 13:00:02,642] [DEBUG] Loading corpus from path: train.spacy\n",
      "\u001b[38;5;4m‚Ñπ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4m‚Ñπ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     21.50    0.00    0.00    0.00    0.00\n",
      "200     200          1.03    263.78    0.00    0.00    0.00    0.00\n",
      "400     400          0.00      0.00    0.00    0.00    0.00    0.00\n",
      "600     600          0.00      0.00    0.00    0.00    0.00    0.00\n",
      "800     800          0.00      0.00    0.00    0.00    0.00    0.00\n",
      "1000    1000          0.00      0.00    0.00    0.00    0.00    0.00\n",
      "1200    1200          0.00      0.00    0.00    0.00    0.00    0.00\n",
      "1400    1400          0.00      0.00    0.00    0.00    0.00    0.00\n",
      "1600    1600          0.00      0.00    0.00    0.00    0.00    0.00\n",
      "\u001b[38;5;2m‚úî Saved pipeline to output directory\u001b[0m\n",
      "output/model-last\n"
     ]
    }
   ],
   "source": [
    "# run the training from the command line:\n",
    "# spacy train config.cfg --output ./output --paths.train ./train.spacy --verbose\n",
    "# or run this notebook cell\n",
    "\n",
    "!python -m spacy train config.cfg --output ./output --paths.train ./train.spacy --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1b45a2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Use the newly fine-tuned model\n",
    "# After training, your new model will be in the 'output/model-best' directory.\n",
    "# You can load it and use it to extract skills.\n",
    "def test_fine_tuned_model(model_path, new_text):\n",
    "    \"\"\"Loads a trained spaCy model and tests it on new text.\"\"\"\n",
    "    try:\n",
    "        nlp_fine_tuned = spacy.load(model_path)\n",
    "        print(f\"\\nSuccessfully loaded fine-tuned model from '{model_path}'\")\n",
    "        doc = nlp_fine_tuned(new_text)\n",
    "        print(f\"\\nText: {new_text}\")\n",
    "        print(\"Extracted Skills:\")\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"SKILL\":\n",
    "                print(f\"- {ent.text} (Label: {ent.label_})\")\n",
    "    except OSError:\n",
    "        print(f\"\\nError: Model not found at '{model_path}'.\")\n",
    "        print(\"Please run 'spacy init config' and 'spacy train' as instructed in the comments.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6c71afaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully loaded fine-tuned model from './output/model-best'\n",
      "\n",
      "Text: I am a skilled web developer with experience in Vue.js and Svelte.\n",
      "Extracted Skills:\n"
     ]
    }
   ],
   "source": [
    "test_fine_tuned_model(\"./output/model-best\", \"I am a skilled web developer with experience in Vue.js and Svelte.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d3bcc8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"./output/model-best\"\n",
    "\n",
    "def load_skill_extractor(model_path: str):\n",
    "    \"\"\"\n",
    "    Loads the trained spaCy model. If the fine-tuned model is not available, \n",
    "    it falls back to a general pre-trained model for demonstration.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. Try to load the custom fine-tuned model\n",
    "        nlp = spacy.load(model_path)\n",
    "        print(f\"Successfully loaded fine-tuned model from '{model_path}'.\")\n",
    "        return nlp\n",
    "    except OSError:\n",
    "        # 2. Fallback if the custom model hasn't been trained yet\n",
    "        print(f\"Custom model not found at '{model_path}'.\")\n",
    "        print(\"Falling back to 'en_core_web_lg' for general entity recognition.\")\n",
    "        try:\n",
    "            nlp = spacy.load(\"en_core_web_lg\")\n",
    "        except OSError:\n",
    "            # Download if the large model is missing\n",
    "            print(\"Downloading 'en_core_web_lg' model. This may take a moment...\")\n",
    "            from spacy.cli import download\n",
    "            download(\"en_core_web_lg\")\n",
    "            nlp = spacy.load(\"en_core_web_lg\")\n",
    "        return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "26ec50e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_skills(nlp_model, text: str) -> list:\n",
    "    \"\"\"\n",
    "    Extracts entities labeled as 'SKILL' from text using the loaded spaCy model.\n",
    "    If the model is the fallback 'en_core_web_lg', it will extract general entities \n",
    "    (like PERSON, ORG) which might contain some skills, but won't use the SKILL label.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "\n",
    "    doc = nlp_model(text)\n",
    "    skills = []\n",
    "\n",
    "    # Check if the 'SKILL' label exists in the model's pipeline\n",
    "    is_fine_tuned = nlp_model.get_pipe(\"ner\").has_label(\"SKILL\") if \"ner\" in nlp_model.pipe_names else False\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        if is_fine_tuned and ent.label_ == \"SKILL\":\n",
    "            # Use the custom SKILL label from your fine-tuned model\n",
    "            skills.append(ent.text)\n",
    "        elif not is_fine_tuned and (ent.label_ in ['ORG', 'PRODUCT', 'MISC']):\n",
    "            # If using the fallback model, look at general entities that often \n",
    "            # catch technology (e.g., Python, AWS are sometimes classified as PRODUCT/ORG/MISC)\n",
    "            skills.append(ent.text)\n",
    "        \n",
    "    return sorted(list(set(skills)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b2ebbe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe_for_skills(df: pd.DataFrame, text_column: str, nlp_model) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Applies the skill extraction function to a DataFrame column.\n",
    "    \"\"\"\n",
    "    if text_column not in df.columns:\n",
    "        print(f\"Error: Column '{text_column}' not found in DataFrame.\")\n",
    "        return df\n",
    "\n",
    "    print(\"Starting skill extraction...\")\n",
    "    # Use a lambda function to pass the model to the extractor\n",
    "    df['extracted_skills'] = df[text_column].apply(lambda x: extract_skills(nlp_model, x))\n",
    "    print(\"Skill extraction complete!\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "75765f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded fine-tuned model from './output/model-best'.\n",
      "\n",
      "------------------------------\n",
      "Sample Data Processing\n",
      "------------------------------\n",
      "Starting skill extraction...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'spacy.pipeline.ner.EntityRecognizer' object has no attribute 'has_label'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m30\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# 3. Apply the skill extraction function.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m extracted_skills_df = \u001b[43mprocess_dataframe_for_skills\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mjob_description\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnlp_skill_extractor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mDataFrame with Extracted Skills:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(extracted_skills_df[[\u001b[33m'\u001b[39m\u001b[33mjob_description\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mextracted_skills\u001b[39m\u001b[33m'\u001b[39m]])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mprocess_dataframe_for_skills\u001b[39m\u001b[34m(df, text_column, nlp_model)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting skill extraction...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Use a lambda function to pass the model to the extractor\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mextracted_skills\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext_column\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mextract_skills\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnlp_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSkill extraction complete!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/pandas/core/series.py:4935\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4800\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4801\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4802\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4807\u001b[39m     **kwargs,\n\u001b[32m   4808\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4809\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4810\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4811\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4926\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4927\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4928\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4929\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4930\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4931\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4932\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4933\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4934\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4935\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/pandas/core/apply.py:1422\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1421\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1422\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/pandas/core/apply.py:1502\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1496\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1498\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1499\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1500\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1501\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1502\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1507\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1508\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/pandas/core/base.py:925\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    923\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/thesis/project_code/NLP_Job_Postings/.venv/lib/python3.13/site-packages/pandas/core/algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:2999\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mprocess_dataframe_for_skills.<locals>.<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting skill extraction...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Use a lambda function to pass the model to the extractor\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mextracted_skills\u001b[39m\u001b[33m'\u001b[39m] = df[text_column].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mextract_skills\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnlp_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSkill extraction complete!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[59]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mextract_skills\u001b[39m\u001b[34m(nlp_model, text)\u001b[39m\n\u001b[32m     11\u001b[39m skills = []\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Check if the 'SKILL' label exists in the model's pipeline\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m is_fine_tuned = \u001b[43mnlp_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_pipe\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mner\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhas_label\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mSKILL\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mner\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m nlp_model.pipe_names \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ent \u001b[38;5;129;01min\u001b[39;00m doc.ents:\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_fine_tuned \u001b[38;5;129;01mand\u001b[39;00m ent.label_ == \u001b[33m\"\u001b[39m\u001b[33mSKILL\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     18\u001b[39m         \u001b[38;5;66;03m# Use the custom SKILL label from your fine-tuned model\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'spacy.pipeline.ner.EntityRecognizer' object has no attribute 'has_label'"
     ]
    }
   ],
   "source": [
    "nlp_skill_extractor = load_skill_extractor(MODEL_PATH)\n",
    "    \n",
    "sample_data = {\n",
    "    'job_description': [\n",
    "        \"We are looking for a data scientist with expertise in Python, machine learning, and SQL databases. Experience with cloud computing platforms like Amazon Web Services (AWS) is a plus. Needs strong project management skills.\",\n",
    "        \"Seeking a software engineer with strong programming skills in Java and C++. Needs a background in web development and agile methodologies. Knowledge of Google Cloud is a plus.\"\n",
    "    ]\n",
    "}\n",
    "sample_df = pd.DataFrame(sample_data)\n",
    "\n",
    "print(\"\\n\" + \"-\"*30)\n",
    "print(\"Sample Data Processing\")\n",
    "print(\"-\"*30)\n",
    "\n",
    "# 3. Apply the skill extraction function.\n",
    "extracted_skills_df = process_dataframe_for_skills(sample_df, 'job_description', nlp_skill_extractor)\n",
    "\n",
    "print(\"\\nDataFrame with Extracted Skills:\")\n",
    "print(extracted_skills_df[['job_description', 'extracted_skills']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed840580",
   "metadata": {},
   "source": [
    "## Labeling our original data\n",
    "The model did not find any skills from the sample dataset of 7 rows, so we will label our original dataset of 1000 entries to train the model.\n",
    "If additional training data won't result in finding the labels successfully we will use a transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ea9beb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: label-studio in ./.venv/lib/python3.13/site-packages (1.21.0)\n",
      "Requirement already satisfied: Django<5.2.0,>=5.1.8 in ./.venv/lib/python3.13/site-packages (from label-studio) (5.1.12)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in ./.venv/lib/python3.13/site-packages (from label-studio) (1.4.4)\n",
      "Requirement already satisfied: attr==0.3.1 in ./.venv/lib/python3.13/site-packages (from label-studio) (0.3.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in ./.venv/lib/python3.13/site-packages (from label-studio) (25.3.0)\n",
      "Requirement already satisfied: azure-storage-blob>=12.6.0 in ./.venv/lib/python3.13/site-packages (from label-studio) (12.26.0)\n",
      "Requirement already satisfied: bleach<5.1.0,>=5.0.0 in ./.venv/lib/python3.13/site-packages (from label-studio) (5.0.1)\n",
      "Requirement already satisfied: boto<3.0.0,>=2.49.0 in ./.venv/lib/python3.13/site-packages (from label-studio) (2.49.0)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.28.58 in ./.venv/lib/python3.13/site-packages (from label-studio) (1.40.42)\n",
      "Requirement already satisfied: botocore<2.0.0,>=1.39.3 in ./.venv/lib/python3.13/site-packages (from label-studio) (1.40.42)\n",
      "Requirement already satisfied: colorama>=0.4.4 in ./.venv/lib/python3.13/site-packages (from label-studio) (0.4.6)\n",
      "Requirement already satisfied: cryptography>=44.0.1 in ./.venv/lib/python3.13/site-packages (from label-studio) (46.0.2)\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in ./.venv/lib/python3.13/site-packages (from label-studio) (0.7.1)\n",
      "Requirement already satisfied: django-annoying==0.10.6 in ./.venv/lib/python3.13/site-packages (from label-studio) (0.10.6)\n",
      "Requirement already satisfied: django-cors-headers==4.7.0 in ./.venv/lib/python3.13/site-packages (from label-studio) (4.7.0)\n",
      "Requirement already satisfied: django-csp==3.7 in ./.venv/lib/python3.13/site-packages (from label-studio) (3.7)\n",
      "Requirement already satisfied: django-debug-toolbar==3.2.1 in ./.venv/lib/python3.13/site-packages (from label-studio) (3.2.1)\n",
      "Requirement already satisfied: django-environ==0.10.0 in ./.venv/lib/python3.13/site-packages (from label-studio) (0.10.0)\n",
      "Requirement already satisfied: django-extensions==3.2.3 in ./.venv/lib/python3.13/site-packages (from label-studio) (3.2.3)\n",
      "Requirement already satisfied: django-filter==24.3 in ./.venv/lib/python3.13/site-packages (from label-studio) (24.3)\n",
      "Requirement already satisfied: django-migration-linter<6.0.0,>=5.1.0 in ./.venv/lib/python3.13/site-packages (from label-studio) (5.2.0)\n",
      "Requirement already satisfied: django-model-utils==4.1.1 in ./.venv/lib/python3.13/site-packages (from label-studio) (4.1.1)\n",
      "Requirement already satisfied: django-ranged-fileresponse>=0.1.2 in ./.venv/lib/python3.13/site-packages (from label-studio) (0.1.2)\n",
      "Requirement already satisfied: django-rq<3.0.0,>=2.10.2 in ./.venv/lib/python3.13/site-packages (from label-studio) (2.10.3)\n",
      "Requirement already satisfied: django-storages==1.12.3 in ./.venv/lib/python3.13/site-packages (from label-studio) (1.12.3)\n",
      "Requirement already satisfied: django-user-agents==0.4.0 in ./.venv/lib/python3.13/site-packages (from label-studio) (0.4.0)\n",
      "Requirement already satisfied: djangorestframework==3.15.2 in ./.venv/lib/python3.13/site-packages (from label-studio) (3.15.2)\n",
      "Requirement already satisfied: djangorestframework-simplejwt<6.0.0,>=5.4.0 in ./.venv/lib/python3.13/site-packages (from djangorestframework-simplejwt[crypto]<6.0.0,>=5.4.0->label-studio) (5.5.1)\n",
      "Requirement already satisfied: drf-dynamic-fields==0.3.0 in ./.venv/lib/python3.13/site-packages (from label-studio) (0.3.0)\n",
      "Requirement already satisfied: drf-flex-fields==0.9.5 in ./.venv/lib/python3.13/site-packages (from label-studio) (0.9.5)\n",
      "Requirement already satisfied: drf-generators==0.3.0 in ./.venv/lib/python3.13/site-packages (from label-studio) (0.3.0)\n",
      "Requirement already satisfied: drf-spectacular==0.28.0 in ./.venv/lib/python3.13/site-packages (from label-studio) (0.28.0)\n",
      "Requirement already satisfied: google-cloud-logging<4.0.0,>=3.10.0 in ./.venv/lib/python3.13/site-packages (from label-studio) (3.12.1)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0,>=2.13.0 in ./.venv/lib/python3.13/site-packages (from label-studio) (2.19.0)\n",
      "Requirement already satisfied: label-studio-sdk==2.0.4 in ./.venv/lib/python3.13/site-packages (from label-studio) (2.0.4)\n",
      "Requirement already satisfied: launchdarkly-server-sdk==8.2.1 in ./.venv/lib/python3.13/site-packages (from label-studio) (8.2.1)\n",
      "Requirement already satisfied: lockfile>=0.12.0 in ./.venv/lib/python3.13/site-packages (from label-studio) (0.12.2)\n",
      "Requirement already satisfied: lxml>=4.9.4 in ./.venv/lib/python3.13/site-packages (from lxml[html-clean]>=4.9.4->label-studio) (6.0.2)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.4 in ./.venv/lib/python3.13/site-packages (from label-studio) (1.26.4)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in ./.venv/lib/python3.13/site-packages (from label-studio) (1.109.1)\n",
      "Requirement already satisfied: ordered-set==4.0.2 in ./.venv/lib/python3.13/site-packages (from label-studio) (4.0.2)\n",
      "Requirement already satisfied: pandas>=2.2.3 in ./.venv/lib/python3.13/site-packages (from label-studio) (2.3.2)\n",
      "Requirement already satisfied: psycopg2-binary==2.9.10 in ./.venv/lib/python3.13/site-packages (from label-studio) (2.9.10)\n",
      "Requirement already satisfied: pyarrow<19.0.0,>=18.1.0 in ./.venv/lib/python3.13/site-packages (from label-studio) (18.1.0)\n",
      "Requirement already satisfied: pyboxen>=1.3.0 in ./.venv/lib/python3.13/site-packages (from label-studio) (1.3.0)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in ./.venv/lib/python3.13/site-packages (from label-studio) (2.11.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./.venv/lib/python3.13/site-packages (from label-studio) (2.9.0.post0)\n",
      "Requirement already satisfied: python-json-logger==2.0.4 in ./.venv/lib/python3.13/site-packages (from label-studio) (2.0.4)\n",
      "Requirement already satisfied: pytz<2023.0,>=2022.1 in ./.venv/lib/python3.13/site-packages (from label-studio) (2022.7.1)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in ./.venv/lib/python3.13/site-packages (from label-studio) (6.0.3)\n",
      "Requirement already satisfied: redis<5.3.0,>=5.2.1 in ./.venv/lib/python3.13/site-packages (from label-studio) (5.2.1)\n",
      "Requirement already satisfied: requests<2.33.0,>=2.32.3 in ./.venv/lib/python3.13/site-packages (from label-studio) (2.32.5)\n",
      "Requirement already satisfied: rq<2.0.0,>=1.16.2 in ./.venv/lib/python3.13/site-packages (from label-studio) (1.16.2)\n",
      "Requirement already satisfied: rules==3.4 in ./.venv/lib/python3.13/site-packages (from label-studio) (3.4)\n",
      "Requirement already satisfied: sentry-sdk>=2.16.0 in ./.venv/lib/python3.13/site-packages (from label-studio) (2.39.0)\n",
      "Requirement already satisfied: setuptools>=75.4.0 in ./.venv/lib/python3.13/site-packages (from label-studio) (80.9.0)\n",
      "Requirement already satisfied: tldextract>=5.1.3 in ./.venv/lib/python3.13/site-packages (from label-studio) (5.3.0)\n",
      "Requirement already satisfied: ujson>=3.0.0 in ./.venv/lib/python3.13/site-packages (from label-studio) (5.11.0)\n",
      "Requirement already satisfied: wheel<=0.40.0,>=0.38.1 in ./.venv/lib/python3.13/site-packages (from label-studio) (0.40.0)\n",
      "Requirement already satisfied: xmljson==0.2.1 in ./.venv/lib/python3.13/site-packages (from label-studio) (0.2.1)\n",
      "Requirement already satisfied: six in ./.venv/lib/python3.13/site-packages (from django-annoying==0.10.6->label-studio) (1.17.0)\n",
      "Requirement already satisfied: asgiref>=3.6 in ./.venv/lib/python3.13/site-packages (from django-cors-headers==4.7.0->label-studio) (3.9.2)\n",
      "Requirement already satisfied: sqlparse>=0.2.0 in ./.venv/lib/python3.13/site-packages (from django-debug-toolbar==3.2.1->label-studio) (0.5.3)\n",
      "Requirement already satisfied: user-agents in ./.venv/lib/python3.13/site-packages (from django-user-agents==0.4.0->label-studio) (2.2.0)\n",
      "Requirement already satisfied: uritemplate>=2.0.0 in ./.venv/lib/python3.13/site-packages (from drf-spectacular==0.28.0->label-studio) (4.2.0)\n",
      "Requirement already satisfied: jsonschema>=2.6.0 in ./.venv/lib/python3.13/site-packages (from drf-spectacular==0.28.0->label-studio) (4.25.1)\n",
      "Requirement already satisfied: inflection>=0.3.1 in ./.venv/lib/python3.13/site-packages (from drf-spectacular==0.28.0->label-studio) (0.5.1)\n",
      "Requirement already satisfied: Pillow>=11.3.0 in ./.venv/lib/python3.13/site-packages (from label-studio-sdk==2.0.4->label-studio) (11.3.0)\n",
      "Requirement already satisfied: datamodel-code-generator==0.26.1 in ./.venv/lib/python3.13/site-packages (from label-studio-sdk==2.0.4->label-studio) (0.26.1)\n",
      "Requirement already satisfied: httpx>=0.21.2 in ./.venv/lib/python3.13/site-packages (from label-studio-sdk==2.0.4->label-studio) (0.28.1)\n",
      "Requirement already satisfied: ijson>=3.2.3 in ./.venv/lib/python3.13/site-packages (from label-studio-sdk==2.0.4->label-studio) (3.4.0)\n",
      "Requirement already satisfied: jsf<0.12.0,>=0.11.2 in ./.venv/lib/python3.13/site-packages (from label-studio-sdk==2.0.4->label-studio) (0.11.2)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.9.1 in ./.venv/lib/python3.13/site-packages (from label-studio-sdk==2.0.4->label-studio) (3.9.2)\n",
      "Requirement already satisfied: opencv-python<5.0.0,>=4.9.0 in ./.venv/lib/python3.13/site-packages (from label-studio-sdk==2.0.4->label-studio) (4.11.0.86)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in ./.venv/lib/python3.13/site-packages (from label-studio-sdk==2.0.4->label-studio) (2.33.2)\n",
      "Requirement already satisfied: pyjwt<3.0.0,>=2.10.1 in ./.venv/lib/python3.13/site-packages (from label-studio-sdk==2.0.4->label-studio) (2.10.1)\n",
      "Requirement already satisfied: requests-mock==1.12.1 in ./.venv/lib/python3.13/site-packages (from label-studio-sdk==2.0.4->label-studio) (1.12.1)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in ./.venv/lib/python3.13/site-packages (from label-studio-sdk==2.0.4->label-studio) (4.15.0)\n",
      "Requirement already satisfied: urllib3>=2.5.0 in ./.venv/lib/python3.13/site-packages (from label-studio-sdk==2.0.4->label-studio) (2.5.0)\n",
      "Requirement already satisfied: argcomplete<4.0,>=1.10 in ./.venv/lib/python3.13/site-packages (from datamodel-code-generator==0.26.1->label-studio-sdk==2.0.4->label-studio) (3.6.2)\n",
      "Requirement already satisfied: black>=19.10b0 in ./.venv/lib/python3.13/site-packages (from datamodel-code-generator==0.26.1->label-studio-sdk==2.0.4->label-studio) (25.9.0)\n",
      "Requirement already satisfied: genson<2.0,>=1.2.1 in ./.venv/lib/python3.13/site-packages (from datamodel-code-generator==0.26.1->label-studio-sdk==2.0.4->label-studio) (1.3.0)\n",
      "Requirement already satisfied: inflect<6.0,>=4.1.0 in ./.venv/lib/python3.13/site-packages (from datamodel-code-generator==0.26.1->label-studio-sdk==2.0.4->label-studio) (5.6.2)\n",
      "Requirement already satisfied: isort<6.0,>=4.3.21 in ./.venv/lib/python3.13/site-packages (from datamodel-code-generator==0.26.1->label-studio-sdk==2.0.4->label-studio) (5.13.2)\n",
      "Requirement already satisfied: jinja2<4.0,>=2.10.1 in ./.venv/lib/python3.13/site-packages (from datamodel-code-generator==0.26.1->label-studio-sdk==2.0.4->label-studio) (3.1.6)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.13/site-packages (from datamodel-code-generator==0.26.1->label-studio-sdk==2.0.4->label-studio) (25.0)\n",
      "Requirement already satisfied: certifi>=2018.4.16 in ./.venv/lib/python3.13/site-packages (from launchdarkly-server-sdk==8.2.1->label-studio) (2025.8.3)\n",
      "Requirement already satisfied: expiringdict>=1.1.4 in ./.venv/lib/python3.13/site-packages (from launchdarkly-server-sdk==8.2.1->label-studio) (1.2.2)\n",
      "Requirement already satisfied: pyRFC3339>=1.0 in ./.venv/lib/python3.13/site-packages (from launchdarkly-server-sdk==8.2.1->label-studio) (2.1.0)\n",
      "Requirement already satisfied: semver>=2.10.2 in ./.venv/lib/python3.13/site-packages (from launchdarkly-server-sdk==8.2.1->label-studio) (3.0.4)\n",
      "Requirement already satisfied: webencodings in ./.venv/lib/python3.13/site-packages (from bleach<5.1.0,>=5.0.0->label-studio) (0.5.1)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in ./.venv/lib/python3.13/site-packages (from boto3<2.0.0,>=1.28.58->label-studio) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in ./.venv/lib/python3.13/site-packages (from boto3<2.0.0,>=1.28.58->label-studio) (0.14.0)\n",
      "Requirement already satisfied: toml>=0.10.2 in ./.venv/lib/python3.13/site-packages (from django-migration-linter<6.0.0,>=5.1.0->label-studio) (0.10.2)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in ./.venv/lib/python3.13/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-logging<4.0.0,>=3.10.0->label-studio) (2.25.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in ./.venv/lib/python3.13/site-packages (from google-cloud-logging<4.0.0,>=3.10.0->label-studio) (2.41.1)\n",
      "Requirement already satisfied: google-cloud-appengine-logging<2.0.0,>=0.1.3 in ./.venv/lib/python3.13/site-packages (from google-cloud-logging<4.0.0,>=3.10.0->label-studio) (1.6.2)\n",
      "Requirement already satisfied: google-cloud-audit-log<1.0.0,>=0.3.1 in ./.venv/lib/python3.13/site-packages (from google-cloud-logging<4.0.0,>=3.10.0->label-studio) (0.3.2)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=2.0.0 in ./.venv/lib/python3.13/site-packages (from google-cloud-logging<4.0.0,>=3.10.0->label-studio) (2.4.3)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.12.4 in ./.venv/lib/python3.13/site-packages (from google-cloud-logging<4.0.0,>=3.10.0->label-studio) (0.14.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.9.0 in ./.venv/lib/python3.13/site-packages (from google-cloud-logging<4.0.0,>=3.10.0->label-studio) (1.37.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.0 in ./.venv/lib/python3.13/site-packages (from google-cloud-logging<4.0.0,>=3.10.0->label-studio) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in ./.venv/lib/python3.13/site-packages (from google-cloud-logging<4.0.0,>=3.10.0->label-studio) (6.32.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in ./.venv/lib/python3.13/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-logging<4.0.0,>=3.10.0->label-studio) (1.70.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in ./.venv/lib/python3.13/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-logging<4.0.0,>=3.10.0->label-studio) (1.75.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in ./.venv/lib/python3.13/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-logging<4.0.0,>=3.10.0->label-studio) (1.75.1)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in ./.venv/lib/python3.13/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-logging<4.0.0,>=3.10.0->label-studio) (6.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.13/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-logging<4.0.0,>=3.10.0->label-studio) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.13/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-logging<4.0.0,>=3.10.0->label-studio) (4.9.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.7.2 in ./.venv/lib/python3.13/site-packages (from google-cloud-storage<3.0.0,>=2.13.0->label-studio) (2.7.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in ./.venv/lib/python3.13/site-packages (from google-cloud-storage<3.0.0,>=2.13.0->label-studio) (1.7.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2<4.0,>=2.10.1->datamodel-code-generator==0.26.1->label-studio-sdk==2.0.4->label-studio) (3.0.2)\n",
      "Requirement already satisfied: faker>=15.3.4 in ./.venv/lib/python3.13/site-packages (from jsf<0.12.0,>=0.11.2->label-studio-sdk==2.0.4->label-studio) (37.8.0)\n",
      "Requirement already satisfied: rstr>=3.2.0 in ./.venv/lib/python3.13/site-packages (from jsf<0.12.0,>=0.11.2->label-studio-sdk==2.0.4->label-studio) (3.2.2)\n",
      "Requirement already satisfied: smart-open>=6.3.0 in ./.venv/lib/python3.13/site-packages (from smart-open[http]>=6.3.0->jsf<0.12.0,>=0.11.2->label-studio-sdk==2.0.4->label-studio) (7.3.1)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.13/site-packages (from nltk<4.0.0,>=3.9.1->label-studio-sdk==2.0.4->label-studio) (8.3.0)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.13/site-packages (from nltk<4.0.0,>=3.9.1->label-studio-sdk==2.0.4->label-studio) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.13/site-packages (from nltk<4.0.0,>=3.9.1->label-studio-sdk==2.0.4->label-studio) (2025.9.18)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.13/site-packages (from nltk<4.0.0,>=3.9.1->label-studio-sdk==2.0.4->label-studio) (4.67.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.10.0->label-studio) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.10.0->label-studio) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.10.0->label-studio) (0.11.0)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.10.0->label-studio) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->label-studio) (3.10)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.13/site-packages (from httpx>=0.21.2->label-studio-sdk==2.0.4->label-studio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.21.2->label-studio-sdk==2.0.4->label-studio) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.13/site-packages (from pydantic>=2.9.2->label-studio) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.13/site-packages (from pydantic>=2.9.2->label-studio) (0.4.1)\n",
      "Requirement already satisfied: email-validator>=2.0.0 in ./.venv/lib/python3.13/site-packages (from pydantic[email]!=2.0.0,!=2.0.1,!=2.4.0,<3.0,>=1.10.0; python_version >= \"3.12\" and python_version < \"4.0\"->datamodel-code-generator==0.26.1->label-studio-sdk==2.0.4->label-studio) (2.3.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests<2.33.0,>=2.32.3->label-studio) (3.4.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in ./.venv/lib/python3.13/site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-logging<4.0.0,>=3.10.0->label-studio) (0.6.1)\n",
      "Requirement already satisfied: azure-core>=1.30.0 in ./.venv/lib/python3.13/site-packages (from azure-storage-blob>=12.6.0->label-studio) (1.35.1)\n",
      "Requirement already satisfied: isodate>=0.6.1 in ./.venv/lib/python3.13/site-packages (from azure-storage-blob>=12.6.0->label-studio) (0.7.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in ./.venv/lib/python3.13/site-packages (from black>=19.10b0->datamodel-code-generator==0.26.1->label-studio-sdk==2.0.4->label-studio) (1.1.0)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in ./.venv/lib/python3.13/site-packages (from black>=19.10b0->datamodel-code-generator==0.26.1->label-studio-sdk==2.0.4->label-studio) (0.12.1)\n",
      "Requirement already satisfied: platformdirs>=2 in ./.venv/lib/python3.13/site-packages (from black>=19.10b0->datamodel-code-generator==0.26.1->label-studio-sdk==2.0.4->label-studio) (4.4.0)\n",
      "Requirement already satisfied: pytokens>=0.1.10 in ./.venv/lib/python3.13/site-packages (from black>=19.10b0->datamodel-code-generator==0.26.1->label-studio-sdk==2.0.4->label-studio) (0.1.10)\n",
      "Requirement already satisfied: cffi>=2.0.0 in ./.venv/lib/python3.13/site-packages (from cryptography>=44.0.1->label-studio) (2.0.0)\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.13/site-packages (from cffi>=2.0.0->cryptography>=44.0.1->label-studio) (2.23)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in ./.venv/lib/python3.13/site-packages (from email-validator>=2.0.0->pydantic[email]!=2.0.0,!=2.0.1,!=2.4.0,<3.0,>=1.10.0; python_version >= \"3.12\" and python_version < \"4.0\"->datamodel-code-generator==0.26.1->label-studio-sdk==2.0.4->label-studio) (2.8.0)\n",
      "Requirement already satisfied: tzdata in ./.venv/lib/python3.13/site-packages (from faker>=15.3.4->jsf<0.12.0,>=0.11.2->label-studio-sdk==2.0.4->label-studio) (2025.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.venv/lib/python3.13/site-packages (from jsonschema>=2.6.0->drf-spectacular==0.28.0->label-studio) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./.venv/lib/python3.13/site-packages (from jsonschema>=2.6.0->drf-spectacular==0.28.0->label-studio) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./.venv/lib/python3.13/site-packages (from jsonschema>=2.6.0->drf-spectacular==0.28.0->label-studio) (0.27.1)\n",
      "Requirement already satisfied: lxml_html_clean in ./.venv/lib/python3.13/site-packages (from lxml[html-clean]>=4.9.4->label-studio) (0.4.2)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in ./.venv/lib/python3.13/site-packages (from opentelemetry-api>=1.9.0->google-cloud-logging<4.0.0,>=3.10.0->label-studio) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in ./.venv/lib/python3.13/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.9.0->google-cloud-logging<4.0.0,>=3.10.0->label-studio) (3.23.0)\n",
      "Requirement already satisfied: rich>=12.5.1 in ./.venv/lib/python3.13/site-packages (from pyboxen>=1.3.0->label-studio) (14.1.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.13/site-packages (from rich>=12.5.1->pyboxen>=1.3.0->label-studio) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.13/site-packages (from rich>=12.5.1->pyboxen>=1.3.0->label-studio) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=12.5.1->pyboxen>=1.3.0->label-studio) (0.1.2)\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.13/site-packages (from smart-open>=6.3.0->smart-open[http]>=6.3.0->jsf<0.12.0,>=0.11.2->label-studio-sdk==2.0.4->label-studio) (1.17.3)\n",
      "Requirement already satisfied: requests-file>=1.4 in ./.venv/lib/python3.13/site-packages (from tldextract>=5.1.3->label-studio) (2.1.0)\n",
      "Requirement already satisfied: filelock>=3.0.8 in ./.venv/lib/python3.13/site-packages (from tldextract>=5.1.3->label-studio) (3.19.1)\n",
      "Requirement already satisfied: ua-parser>=0.10.0 in ./.venv/lib/python3.13/site-packages (from user-agents->django-user-agents==0.4.0->label-studio) (1.0.1)\n",
      "Requirement already satisfied: ua-parser-builtins in ./.venv/lib/python3.13/site-packages (from ua-parser>=0.10.0->user-agents->django-user-agents==0.4.0->label-studio) (0.18.0.post1)\n"
     ]
    }
   ],
   "source": [
    "# Install label-studio open source platform for data labeling\n",
    "!python -m pip install label-studio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396046a8",
   "metadata": {},
   "source": [
    "## Start label-studio in terminal using this command:\n",
    "label-studio start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c321dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/juliabarsow/Desktop/thesis/project_code/NLP_Job_Postings/.venv/bin/python: No module named label-studio\n"
     ]
    }
   ],
   "source": [
    "# Start Label Studio in terminal:\n",
    "# label-studio start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad073248",
   "metadata": {},
   "source": [
    "### NEXT STEPS\n",
    "\n",
    "1. Skill Extraction - NER model for skills\n",
    "Use a model trained to recognize skills (e.g., SpaCy custom NER, or libraries like SkillNer, Pyresparser, or ESCO-based tools).\n",
    "\n",
    "2. Associate Skills with Job Titles\n",
    "\n",
    "example:\n",
    "skills_by_job = {}\n",
    "\n",
    "for title, description in zip(job_titles, job_descriptions):\n",
    "    doc = nlp(description.lower())\n",
    "    tokens = [token.lemma_ for token in doc if token.lemma_ in skill_set]\n",
    "    skills_by_job[title] = tokens\n",
    "\n",
    "\n",
    "3. Clustering Skills into Categories - Automated clustering with embeddings (advanced)\n",
    "Use word embeddings (like word2vec, spaCy, or sentence-transformers) + KMeans to group similar skills.\n",
    "\n",
    "example:\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "--- Get unique skills\n",
    "unique_skills = list(set(extracted_skills))\n",
    "\n",
    "--- Get spaCy vector for each skill\n",
    "skill_vectors = [nlp(skill).vector for skill in unique_skills]\n",
    "\n",
    "--- Cluster with KMeans\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "labels = kmeans.fit_predict(skill_vectors)\n",
    "\n",
    "--- Map each skill to its cluster\n",
    "clusters = {}\n",
    "for skill, label in zip(unique_skills, labels):\n",
    "    clusters.setdefault(label, []).append(skill)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
